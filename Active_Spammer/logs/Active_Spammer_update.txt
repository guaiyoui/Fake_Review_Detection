usage: run_baselines.py [-h] [--no-cuda] [--seed SEED] [--epochs EPOCHS]
                        [--lr LR] [--weight_decay WEIGHT_DECAY]
                        [--hidden HIDDEN] [--dropout DROPOUT]
                        [--dataset DATASET] [--model {SGC,GCN}]
                        [--feature {non,mul,cat,adj}]
                        [--normalization {AugNormAdj}] [--degree DEGREE]
                        [--per PER] [--experiment EXPERIMENT] [--tuned]
                        [--strategy STRATEGY] [--file_io FILE_IO]
                        [--reweight {0,1}] [--adaptive {0,1}]
                        [--lambdaa LAMBDAA]
                        [--weight_loss_subgraph WEIGHT_LOSS_SUBGRAPH]
                        [--weight_loss_reconstruction WEIGHT_LOSS_RECONSTRUCTION]
                        [--weight_kl_loss WEIGHT_KL_LOSS]
                        [--weight_t_loss WEIGHT_T_LOSS]
                        [--save_name SAVE_NAME] [--data_path DATA_PATH]
                        [--test_percents TEST_PERCENTS] [--sample_global]
run_baselines.py: error: argument --model: invalid choice: 'GCN_update' (choose from 'SGC', 'GCN')
usage: run_baselines.py [-h] [--no-cuda] [--seed SEED] [--epochs EPOCHS]
                        [--lr LR] [--weight_decay WEIGHT_DECAY]
                        [--hidden HIDDEN] [--dropout DROPOUT]
                        [--dataset DATASET] [--model {SGC,GCN}]
                        [--feature {non,mul,cat,adj}]
                        [--normalization {AugNormAdj}] [--degree DEGREE]
                        [--per PER] [--experiment EXPERIMENT] [--tuned]
                        [--strategy STRATEGY] [--file_io FILE_IO]
                        [--reweight {0,1}] [--adaptive {0,1}]
                        [--lambdaa LAMBDAA]
                        [--weight_loss_subgraph WEIGHT_LOSS_SUBGRAPH]
                        [--weight_loss_reconstruction WEIGHT_LOSS_RECONSTRUCTION]
                        [--weight_kl_loss WEIGHT_KL_LOSS]
                        [--weight_t_loss WEIGHT_T_LOSS]
                        [--save_name SAVE_NAME] [--data_path DATA_PATH]
                        [--test_percents TEST_PERCENTS] [--sample_global]
run_baselines.py: error: argument --model: invalid choice: 'GCN_update' (choose from 'SGC', 'GCN')
usage: run_baselines.py [-h] [--no-cuda] [--seed SEED] [--epochs EPOCHS]
                        [--lr LR] [--weight_decay WEIGHT_DECAY]
                        [--hidden HIDDEN] [--dropout DROPOUT]
                        [--dataset DATASET] [--model {SGC,GCN}]
                        [--feature {non,mul,cat,adj}]
                        [--normalization {AugNormAdj}] [--degree DEGREE]
                        [--per PER] [--experiment EXPERIMENT] [--tuned]
                        [--strategy STRATEGY] [--file_io FILE_IO]
                        [--reweight {0,1}] [--adaptive {0,1}]
                        [--lambdaa LAMBDAA]
                        [--weight_loss_subgraph WEIGHT_LOSS_SUBGRAPH]
                        [--weight_loss_reconstruction WEIGHT_LOSS_RECONSTRUCTION]
                        [--weight_kl_loss WEIGHT_KL_LOSS]
                        [--weight_t_loss WEIGHT_T_LOSS]
                        [--save_name SAVE_NAME] [--data_path DATA_PATH]
                        [--test_percents TEST_PERCENTS] [--sample_global]
run_baselines.py: error: argument --model: invalid choice: 'GCN_update' (choose from 'SGC', 'GCN')
usage: run_baselines.py [-h] [--no-cuda] [--seed SEED] [--epochs EPOCHS]
                        [--lr LR] [--weight_decay WEIGHT_DECAY]
                        [--hidden HIDDEN] [--dropout DROPOUT]
                        [--dataset DATASET] [--model {SGC,GCN}]
                        [--feature {non,mul,cat,adj}]
                        [--normalization {AugNormAdj}] [--degree DEGREE]
                        [--per PER] [--experiment EXPERIMENT] [--tuned]
                        [--strategy STRATEGY] [--file_io FILE_IO]
                        [--reweight {0,1}] [--adaptive {0,1}]
                        [--lambdaa LAMBDAA]
                        [--weight_loss_subgraph WEIGHT_LOSS_SUBGRAPH]
                        [--weight_loss_reconstruction WEIGHT_LOSS_RECONSTRUCTION]
                        [--weight_kl_loss WEIGHT_KL_LOSS]
                        [--weight_t_loss WEIGHT_T_LOSS]
                        [--save_name SAVE_NAME] [--data_path DATA_PATH]
                        [--test_percents TEST_PERCENTS] [--sample_global]
run_baselines.py: error: argument --model: invalid choice: 'GCN_update' (choose from 'SGC', 'GCN')
usage: run_baselines.py [-h] [--no-cuda] [--seed SEED] [--epochs EPOCHS]
                        [--lr LR] [--weight_decay WEIGHT_DECAY]
                        [--hidden HIDDEN] [--dropout DROPOUT]
                        [--dataset DATASET] [--model {SGC,GCN}]
                        [--feature {non,mul,cat,adj}]
                        [--normalization {AugNormAdj}] [--degree DEGREE]
                        [--per PER] [--experiment EXPERIMENT] [--tuned]
                        [--strategy STRATEGY] [--file_io FILE_IO]
                        [--reweight {0,1}] [--adaptive {0,1}]
                        [--lambdaa LAMBDAA]
                        [--weight_loss_subgraph WEIGHT_LOSS_SUBGRAPH]
                        [--weight_loss_reconstruction WEIGHT_LOSS_RECONSTRUCTION]
                        [--weight_kl_loss WEIGHT_KL_LOSS]
                        [--weight_t_loss WEIGHT_T_LOSS]
                        [--save_name SAVE_NAME] [--data_path DATA_PATH]
                        [--test_percents TEST_PERCENTS] [--sample_global]
run_baselines.py: error: argument --model: invalid choice: 'GCN_update' (choose from 'SGC', 'GCN')
usage: run_baselines.py [-h] [--no-cuda] [--seed SEED] [--epochs EPOCHS]
                        [--lr LR] [--weight_decay WEIGHT_DECAY]
                        [--hidden HIDDEN] [--dropout DROPOUT]
                        [--dataset DATASET] [--model {SGC,GCN}]
                        [--feature {non,mul,cat,adj}]
                        [--normalization {AugNormAdj}] [--degree DEGREE]
                        [--per PER] [--experiment EXPERIMENT] [--tuned]
                        [--strategy STRATEGY] [--file_io FILE_IO]
                        [--reweight {0,1}] [--adaptive {0,1}]
                        [--lambdaa LAMBDAA]
                        [--weight_loss_subgraph WEIGHT_LOSS_SUBGRAPH]
                        [--weight_loss_reconstruction WEIGHT_LOSS_RECONSTRUCTION]
                        [--weight_kl_loss WEIGHT_KL_LOSS]
                        [--weight_t_loss WEIGHT_T_LOSS]
                        [--save_name SAVE_NAME] [--data_path DATA_PATH]
                        [--test_percents TEST_PERCENTS] [--sample_global]
run_baselines.py: error: argument --model: invalid choice: 'GCN_update' (choose from 'SGC', 'GCN')
usage: run_baselines.py [-h] [--no-cuda] [--seed SEED] [--epochs EPOCHS]
                        [--lr LR] [--weight_decay WEIGHT_DECAY]
                        [--hidden HIDDEN] [--dropout DROPOUT]
                        [--dataset DATASET] [--model {SGC,GCN}]
                        [--feature {non,mul,cat,adj}]
                        [--normalization {AugNormAdj}] [--degree DEGREE]
                        [--per PER] [--experiment EXPERIMENT] [--tuned]
                        [--strategy STRATEGY] [--file_io FILE_IO]
                        [--reweight {0,1}] [--adaptive {0,1}]
                        [--lambdaa LAMBDAA]
                        [--weight_loss_subgraph WEIGHT_LOSS_SUBGRAPH]
                        [--weight_loss_reconstruction WEIGHT_LOSS_RECONSTRUCTION]
                        [--weight_kl_loss WEIGHT_KL_LOSS]
                        [--weight_t_loss WEIGHT_T_LOSS]
                        [--save_name SAVE_NAME] [--data_path DATA_PATH]
                        [--test_percents TEST_PERCENTS] [--sample_global]
run_baselines.py: error: argument --model: invalid choice: 'GCN_update' (choose from 'SGC', 'GCN')
usage: run_baselines.py [-h] [--no-cuda] [--seed SEED] [--epochs EPOCHS]
                        [--lr LR] [--weight_decay WEIGHT_DECAY]
                        [--hidden HIDDEN] [--dropout DROPOUT]
                        [--dataset DATASET] [--model {SGC,GCN}]
                        [--feature {non,mul,cat,adj}]
                        [--normalization {AugNormAdj}] [--degree DEGREE]
                        [--per PER] [--experiment EXPERIMENT] [--tuned]
                        [--strategy STRATEGY] [--file_io FILE_IO]
                        [--reweight {0,1}] [--adaptive {0,1}]
                        [--lambdaa LAMBDAA]
                        [--weight_loss_subgraph WEIGHT_LOSS_SUBGRAPH]
                        [--weight_loss_reconstruction WEIGHT_LOSS_RECONSTRUCTION]
                        [--weight_kl_loss WEIGHT_KL_LOSS]
                        [--weight_t_loss WEIGHT_T_LOSS]
                        [--save_name SAVE_NAME] [--data_path DATA_PATH]
                        [--test_percents TEST_PERCENTS] [--sample_global]
run_baselines.py: error: argument --model: invalid choice: 'GCN_update' (choose from 'SGC', 'GCN')
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 4187, self.idx_non_test is 4187
finished loading dataset
current seed is 300
len(idx_non_test) is 4187
len(idx_non_test): 4172
-------------initial results------------
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 439, in run
    print('micro_val: {:.4f}, macro_val: {:.4f}'.format(micro_val, macro_val))
UnboundLocalError: local variable 'micro_val' referenced before assignment
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 4187, self.idx_non_test is 4187
finished loading dataset
current seed is 300
len(idx_non_test) is 4187
len(idx_non_test): 4172
-------------initial results------------
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 439, in run
    print('micro_val: {:.4f}, macro_val: {:.4f}'.format(micro_val, macro_val))
UnboundLocalError: local variable 'micro_val' referenced before assignment
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 5862, self.idx_non_test is 2512
finished loading dataset
current seed is 300
len(idx_non_test) is 2512
len(idx_non_test): 2497
-------------initial results------------
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 439, in run
    print('micro_val: {:.4f}, macro_val: {:.4f}'.format(micro_val, macro_val))
UnboundLocalError: local variable 'micro_val' referenced before assignment
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 5862, self.idx_non_test is 2512
finished loading dataset
current seed is 300
len(idx_non_test) is 2512
len(idx_non_test): 2497
-------------initial results------------
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 439, in run
    print('micro_val: {:.4f}, macro_val: {:.4f}'.format(micro_val, macro_val))
UnboundLocalError: local variable 'micro_val' referenced before assignment
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7537, self.idx_non_test is 837
finished loading dataset
current seed is 300
len(idx_non_test) is 837
len(idx_non_test): 822
-------------initial results------------
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 439, in run
    print('micro_val: {:.4f}, macro_val: {:.4f}'.format(micro_val, macro_val))
UnboundLocalError: local variable 'micro_val' referenced before assignment
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7537, self.idx_non_test is 837
finished loading dataset
current seed is 300
len(idx_non_test) is 837
len(idx_non_test): 822
-------------initial results------------
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 439, in run
    print('micro_val: {:.4f}, macro_val: {:.4f}'.format(micro_val, macro_val))
UnboundLocalError: local variable 'micro_val' referenced before assignment
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7955, self.idx_non_test is 419
finished loading dataset
current seed is 300
len(idx_non_test) is 419
len(idx_non_test): 404
macro_val: 0.6703296703296704
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5714285714285715
-------------initial results------------
micro_val: 0.7000, macro_val: 0.6703
strategy:  uncertainty
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 471, in run
    idx_train = query_uncertainty(model, self.features, budget, pool)
  File "/data1/jianweiw/LLM/Imputation/Fake_review_detection/Fake_Review_Detection/Active_Spammer/sampling_methods.py", line 169, in query_uncertainty
    output = model(features[nodes_idx])
  File "/data1/jianweiw/env_conda/imputation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/data1/jianweiw/env_conda/imputation/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
TypeError: forward() missing 1 required positional argument: 'edge_index'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7955, self.idx_non_test is 419
finished loading dataset
current seed is 300
len(idx_non_test) is 419
len(idx_non_test): 404
macro_val: 0.6703296703296704
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5714285714285715
-------------initial results------------
micro_val: 0.7000, macro_val: 0.6703
strategy:  uncertainty
============sample global=======
7945
8349
the number of labels is 10
f1_val_isr: 0.5714285714285715
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 518, in run
    print('f1_test_isr: {}'.format(f1_test))
UnboundLocalError: local variable 'f1_test' referenced before assignment
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 4187, self.idx_non_test is 4187
finished loading dataset
current seed is 300
len(idx_non_test) is 4187
len(idx_non_test): 4172
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
-------------initial results------------
micro_val: 0.8000, macro_val: 0.6875
strategy:  uncertainty
============sample only in training=======
4187
8349
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 10
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 514, in run
    macro_test_all, f1_test_all, macro_test, f1_test = test_GCN(model, self.adj, self.features, test_idx_in_test, self.labels[test_idx_in_test], all_test_idx, self.labels[all_test_idx], save_name=args.test_percents, dataset_name=args.dataset, sample_global=args.sample_global)
  File "run_baselines.py", line 230, in test_GCN
    with open(path, 'w') as file:
FileNotFoundError: [Errno 2] No such file or directory: './spammer_results_updates/amazon/50percent_all.txt'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 4187, self.idx_non_test is 4187
finished loading dataset
current seed is 300
len(idx_non_test) is 4187
len(idx_non_test): 4172
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
-------------initial results------------
micro_val: 0.8000, macro_val: 0.6875
strategy:  uncertainty
============sample global=======
4181
8349
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 10
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 514, in run
    macro_test_all, f1_test_all, macro_test, f1_test = test_GCN(model, self.adj, self.features, test_idx_in_test, self.labels[test_idx_in_test], all_test_idx, self.labels[all_test_idx], save_name=args.test_percents, dataset_name=args.dataset, sample_global=args.sample_global)
  File "run_baselines.py", line 230, in test_GCN
    with open(path, 'w') as file:
FileNotFoundError: [Errno 2] No such file or directory: './spammer_results_updates/amazon/50percent_all_sample_global.txt'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 5862, self.idx_non_test is 2512
finished loading dataset
current seed is 300
len(idx_non_test) is 2512
len(idx_non_test): 2497
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
-------------initial results------------
micro_val: 0.7000, macro_val: 0.4118
strategy:  uncertainty
============sample only in training=======
5862
8349
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 10
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 514, in run
    macro_test_all, f1_test_all, macro_test, f1_test = test_GCN(model, self.adj, self.features, test_idx_in_test, self.labels[test_idx_in_test], all_test_idx, self.labels[all_test_idx], save_name=args.test_percents, dataset_name=args.dataset, sample_global=args.sample_global)
  File "run_baselines.py", line 230, in test_GCN
    with open(path, 'w') as file:
FileNotFoundError: [Errno 2] No such file or directory: './spammer_results_updates/amazon/30percent_all.txt'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 5862, self.idx_non_test is 2512
finished loading dataset
current seed is 300
len(idx_non_test) is 2512
len(idx_non_test): 2497
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
-------------initial results------------
micro_val: 0.7000, macro_val: 0.4118
strategy:  uncertainty
============sample global=======
5853
8349
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 10
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 514, in run
    macro_test_all, f1_test_all, macro_test, f1_test = test_GCN(model, self.adj, self.features, test_idx_in_test, self.labels[test_idx_in_test], all_test_idx, self.labels[all_test_idx], save_name=args.test_percents, dataset_name=args.dataset, sample_global=args.sample_global)
  File "run_baselines.py", line 230, in test_GCN
    with open(path, 'w') as file:
FileNotFoundError: [Errno 2] No such file or directory: './spammer_results_updates/amazon/30percent_all_sample_global.txt'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7537, self.idx_non_test is 837
finished loading dataset
current seed is 300
len(idx_non_test) is 837
len(idx_non_test): 822
macro_val: 0.37499999999999994
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
-------------initial results------------
micro_val: 0.6000, macro_val: 0.3750
strategy:  uncertainty
============sample only in training=======
7537
8349
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 10
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 514, in run
    macro_test_all, f1_test_all, macro_test, f1_test = test_GCN(model, self.adj, self.features, test_idx_in_test, self.labels[test_idx_in_test], all_test_idx, self.labels[all_test_idx], save_name=args.test_percents, dataset_name=args.dataset, sample_global=args.sample_global)
  File "run_baselines.py", line 230, in test_GCN
    with open(path, 'w') as file:
FileNotFoundError: [Errno 2] No such file or directory: './spammer_results_updates/amazon/10percent_all.txt'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7537, self.idx_non_test is 837
finished loading dataset
current seed is 300
len(idx_non_test) is 837
len(idx_non_test): 822
macro_val: 0.37499999999999994
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
-------------initial results------------
micro_val: 0.6000, macro_val: 0.3750
strategy:  uncertainty
============sample global=======
7529
8349
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 10
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 514, in run
    macro_test_all, f1_test_all, macro_test, f1_test = test_GCN(model, self.adj, self.features, test_idx_in_test, self.labels[test_idx_in_test], all_test_idx, self.labels[all_test_idx], save_name=args.test_percents, dataset_name=args.dataset, sample_global=args.sample_global)
  File "run_baselines.py", line 230, in test_GCN
    with open(path, 'w') as file:
FileNotFoundError: [Errno 2] No such file or directory: './spammer_results_updates/amazon/10percent_all_sample_global.txt'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7955, self.idx_non_test is 419
finished loading dataset
current seed is 300
len(idx_non_test) is 419
len(idx_non_test): 404
macro_val: 0.6703296703296704
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5714285714285715
-------------initial results------------
micro_val: 0.7000, macro_val: 0.6703
strategy:  uncertainty
============sample only in training=======
7955
8349
macro_val: 0.5238095238095238
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.3333333333333333
the number of labels is 10
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 514, in run
    macro_test_all, f1_test_all, macro_test, f1_test = test_GCN(model, self.adj, self.features, test_idx_in_test, self.labels[test_idx_in_test], all_test_idx, self.labels[all_test_idx], save_name=args.test_percents, dataset_name=args.dataset, sample_global=args.sample_global)
  File "run_baselines.py", line 230, in test_GCN
    with open(path, 'w') as file:
FileNotFoundError: [Errno 2] No such file or directory: './spammer_results_updates/amazon/5percent_all.txt'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7955, self.idx_non_test is 419
finished loading dataset
current seed is 300
len(idx_non_test) is 419
len(idx_non_test): 404
macro_val: 0.6703296703296704
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5714285714285715
-------------initial results------------
micro_val: 0.7000, macro_val: 0.6703
strategy:  uncertainty
============sample global=======
7946
8349
macro_val: 0.6703296703296704
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5714285714285715
the number of labels is 10
Traceback (most recent call last):
  File "run_baselines.py", line 577, in <module>
    val_dict, test_dict, classes_dict, cur_AL_time = wrapper.run(args.strategy, num_labeled_list=num_labeled_list,
  File "run_baselines.py", line 514, in run
    macro_test_all, f1_test_all, macro_test, f1_test = test_GCN(model, self.adj, self.features, test_idx_in_test, self.labels[test_idx_in_test], all_test_idx, self.labels[all_test_idx], save_name=args.test_percents, dataset_name=args.dataset, sample_global=args.sample_global)
  File "run_baselines.py", line 230, in test_GCN
    with open(path, 'w') as file:
FileNotFoundError: [Errno 2] No such file or directory: './spammer_results_updates/amazon/5percent_all_sample_global.txt'
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 4187, self.idx_non_test is 4187
finished loading dataset
current seed is 300
len(idx_non_test) is 4187
len(idx_non_test): 4172
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
-------------initial results------------
micro_val: 0.8000, macro_val: 0.6875
strategy:  uncertainty
============sample only in training=======
4187
8349
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 10
preds.shape: (8349,), labels.shape: (8349,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8467437454724451, f1_test_all: 0.7238670694864048, macro_test: 0.8420622362869198, f1_test: 0.7139240506329114
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7139240506329114
============sample only in training=======
4187
8339
macro_val: 0.6
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.4
the number of labels is 20
preds.shape: (8339,), labels.shape: (8339,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.6359871287188297, f1_test_all: 0.37599664288711715, macro_test: 0.6265145277304562, f1_test: 0.3577512776831345
f1_val_isr: 0.4
f1_test_isr: 0.3577512776831345
============sample only in training=======
4187
8329
macro_val: 0.4444444444444445
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 30
preds.shape: (8329,), labels.shape: (8329,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.6932455276584794, f1_test_all: 0.45057471264367815, macro_test: 0.6847759625052138, f1_test: 0.4340723453908985
f1_val_isr: 0.0
f1_test_isr: 0.4340723453908985
============sample only in training=======
4187
8319
macro_val: 0.4444444444444445
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 40
preds.shape: (8319,), labels.shape: (8319,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.7849170196001183, f1_test_all: 0.6181818181818182, macro_test: 0.7781325056414905, f1_test: 0.6048034934497816
f1_val_isr: 0.0
f1_test_isr: 0.6048034934497816
============sample only in training=======
4187
8309
macro_val: 0.4444444444444445
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 50
preds.shape: (8309,), labels.shape: (8309,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.7547532366668683, f1_test_all: 0.5615428247305728, macro_test: 0.7494891060032167, f1_test: 0.5510907003444316
f1_val_isr: 0.0
f1_test_isr: 0.5510907003444316
============sample only in training=======
4187
8299
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 60
preds.shape: (8299,), labels.shape: (8299,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.802771841004009, f1_test_all: 0.6498659517426274, macro_test: 0.7908253919832706, f1_test: 0.627062706270627
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.627062706270627
============sample only in training=======
4187
8289
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 70
preds.shape: (8289,), labels.shape: (8289,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.7940049620391578, f1_test_all: 0.633587786259542, macro_test: 0.7937660946201837, f1_test: 0.6318131256952169
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.6318131256952169
============sample only in training=======
4187
8279
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 80
preds.shape: (8279,), labels.shape: (8279,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8535075657264255, f1_test_all: 0.7412008281573499, macro_test: 0.8488303776860942, f1_test: 0.7317073170731706
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7317073170731706
============sample only in training=======
4187
8269
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 90
preds.shape: (8269,), labels.shape: (8269,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8771299756462277, f1_test_all: 0.783101494075219, macro_test: 0.8660563664440186, f1_test: 0.7624076029567054
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7624076029567054
============sample only in training=======
4187
8259
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 100
preds.shape: (8259,), labels.shape: (8259,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8815916308548974, f1_test_all: 0.7911975435005119, macro_test: 0.8734064268171007, f1_test: 0.7758081334723671
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7758081334723671
============sample only in training=======
4187
8249
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 110
preds.shape: (8249,), labels.shape: (8249,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8753041652793437, f1_test_all: 0.7794656888423259, macro_test: 0.8627001733695281, f1_test: 0.7563559322033898
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7563559322033898
============sample only in training=======
4187
8239
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 120
preds.shape: (8239,), labels.shape: (8239,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8821817320439983, f1_test_all: 0.7912904938927243, macro_test: 0.8715394976386588, f1_test: 0.7717041800643087
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7717041800643087
============sample only in training=======
4187
8229
macro_val: 0.4444444444444445
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 130
preds.shape: (8229,), labels.shape: (8229,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8924051831412649, f1_test_all: 0.8085808580858085, macro_test: 0.8862684708478202, f1_test: 0.796875
f1_val_isr: 0.0
f1_test_isr: 0.796875
============sample only in training=======
4187
8219
macro_val: 0.4444444444444445
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 140
preds.shape: (8219,), labels.shape: (8219,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8948482385897509, f1_test_all: 0.8122518434486671, macro_test: 0.8893049717632244, f1_test: 0.8018223234624146
f1_val_isr: 0.0
f1_test_isr: 0.8018223234624146
============sample only in training=======
4187
8209
macro_val: 0.4444444444444445
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 150
preds.shape: (8209,), labels.shape: (8209,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.89648828994095, f1_test_all: 0.8150684931506849, macro_test: 0.8881057936070531, f1_test: 0.799541809851088
f1_val_isr: 0.0
f1_test_isr: 0.799541809851088
============sample only in training=======
4187
8199
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 160
preds.shape: (8199,), labels.shape: (8199,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8948268909921979, f1_test_all: 0.8119608970672801, macro_test: 0.8875801678108315, f1_test: 0.7986270022883295
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7986270022883295
============sample only in training=======
4187
8189
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 170
preds.shape: (8189,), labels.shape: (8189,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.8997213927802339, f1_test_all: 0.820835718374356, macro_test: 0.8899682230908179, f1_test: 0.8031674208144797
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8031674208144797
============sample only in training=======
4187
8179
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 180
preds.shape: (8179,), labels.shape: (8179,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9026915285155188, f1_test_all: 0.826036866359447, macro_test: 0.8917573114917969, f1_test: 0.8063420158550396
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8063420158550396
============sample only in training=======
4187
8169
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 190
preds.shape: (8169,), labels.shape: (8169,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.90514412422651, f1_test_all: 0.8303416328894035, macro_test: 0.8959890271083765, f1_test: 0.8137142857142858
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8137142857142858
============sample only in training=======
4187
8159
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 200
preds.shape: (8159,), labels.shape: (8159,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9057648069025066, f1_test_all: 0.8313953488372093, macro_test: 0.8938649277751342, f1_test: 0.8100113765642776
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8100113765642776
============sample only in training=======
4187
8149
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 210
preds.shape: (8149,), labels.shape: (8149,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9138318876581867, f1_test_all: 0.8458406050029087, macro_test: 0.9024207832269764, f1_test: 0.8253968253968254
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8253968253968254
============sample only in training=======
4187
8139
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 220
preds.shape: (8139,), labels.shape: (8139,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9132982011572636, f1_test_all: 0.8447058823529412, macro_test: 0.902762478740093, f1_test: 0.825938566552901
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.825938566552901
============sample only in training=======
4187
8129
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 230
preds.shape: (8129,), labels.shape: (8129,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9133891461713393, f1_test_all: 0.8448377581120943, macro_test: 0.9022755564737616, f1_test: 0.8252536640360767
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8252536640360767
============sample only in training=======
4187
8119
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 240
preds.shape: (8119,), labels.shape: (8119,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9200473803027929, f1_test_all: 0.8568061284619917, macro_test: 0.9118026563764015, f1_test: 0.8424581005586592
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8424581005586592
============sample only in training=======
4187
8109
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 250
preds.shape: (8109,), labels.shape: (8109,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9261895028711666, f1_test_all: 0.8678802113916617, macro_test: 0.9187867652245059, f1_test: 0.8552631578947368
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8552631578947368
============sample only in training=======
4187
8099
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 260
preds.shape: (8099,), labels.shape: (8099,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9287338422441158, f1_test_all: 0.872514619883041, macro_test: 0.9194854841496414, f1_test: 0.8568353067814855
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8568353067814855
============sample only in training=======
4187
8089
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 270
preds.shape: (8089,), labels.shape: (8089,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9313549333847729, f1_test_all: 0.8770685579196218, macro_test: 0.9249392830105282, f1_test: 0.8662280701754386
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8662280701754386
============sample only in training=======
4187
8079
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 280
preds.shape: (8079,), labels.shape: (8079,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9322998890968932, f1_test_all: 0.8787699586043761, macro_test: 0.9261929954679436, f1_test: 0.8686210640608035
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8686210640608035
============sample only in training=======
4187
8069
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 290
preds.shape: (8069,), labels.shape: (8069,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9335770957630849, f1_test_all: 0.8809096349491322, macro_test: 0.928904338824345, f1_test: 0.8733624454148472
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8733624454148472
============sample only in training=======
4187
8059
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 300
preds.shape: (8059,), labels.shape: (8059,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9366374547005833, f1_test_all: 0.8863499699338545, macro_test: 0.928904338824345, f1_test: 0.8733624454148472
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8733624454148472
============sample only in training=======
4187
8049
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 310
preds.shape: (8049,), labels.shape: (8049,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9447574302939865, f1_test_all: 0.9007912355447353, macro_test: 0.9376795415643373, f1_test: 0.888888888888889
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.888888888888889
============sample only in training=======
4187
8039
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 320
preds.shape: (8039,), labels.shape: (8039,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9444497647918907, f1_test_all: 0.9001837109614207, macro_test: 0.9353363163137928, f1_test: 0.8847420417124039
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8847420417124039
============sample only in training=======
4187
8029
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 330
preds.shape: (8029,), labels.shape: (8029,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9466085731242145, f1_test_all: 0.9038701622971286, macro_test: 0.9380742055408775, f1_test: 0.8893854748603353
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8893854748603353
============sample only in training=======
4187
8019
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 340
preds.shape: (8019,), labels.shape: (8019,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9460009256039689, f1_test_all: 0.9026548672566372, macro_test: 0.936008752845394, f1_test: 0.8856502242152466
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8856502242152466
============sample only in training=======
4187
8009
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 350
preds.shape: (8009,), labels.shape: (8009,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9471700929907182, f1_test_all: 0.9048811013767208, macro_test: 0.9378416660553792, f1_test: 0.8893709327548808
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8893709327548808
============sample only in training=======
4187
7999
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 360
preds.shape: (7999,), labels.shape: (7999,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9488593135635662, f1_test_all: 0.9076923076923077, macro_test: 0.940692892615019, f1_test: 0.8940914158305462
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8940914158305462
============sample only in training=======
4187
7989
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 370
preds.shape: (7989,), labels.shape: (7989,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9462564970471187, f1_test_all: 0.903061224489796, macro_test: 0.9360742259322845, f1_test: 0.8862405200433369
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8862405200433369
============sample only in training=======
4187
7979
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 380
preds.shape: (7979,), labels.shape: (7979,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9474490537238198, f1_test_all: 0.9051000645577792, macro_test: 0.9368114362156108, f1_test: 0.8874316939890711
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8874316939890711
============sample only in training=======
4187
7969
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 390
preds.shape: (7969,), labels.shape: (7969,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9500140816399378, f1_test_all: 0.9096816114359975, macro_test: 0.9384748221397772, f1_test: 0.8903508771929826
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8903508771929826
============sample only in training=======
4187
7959
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 400
preds.shape: (7959,), labels.shape: (7959,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9439948381317083, f1_test_all: 0.898453261600538, macro_test: 0.9264695215132064, f1_test: 0.8682703321878579
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8682703321878579
============sample only in training=======
4187
7949
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 410
preds.shape: (7949,), labels.shape: (7949,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9502158808581644, f1_test_all: 0.910039113428944, macro_test: 0.9375698927937733, f1_test: 0.8891257995735607
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8891257995735607
============sample only in training=======
4187
7939
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 420
preds.shape: (7939,), labels.shape: (7939,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9519099745911475, f1_test_all: 0.9127789046653144, macro_test: 0.9387215750709326, f1_test: 0.8903954802259886
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8903954802259886
============sample only in training=======
4187
7929
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 430
preds.shape: (7929,), labels.shape: (7929,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9558462675874793, f1_test_all: 0.9199731002017485, macro_test: 0.9431779426498511, f1_test: 0.8986784140969162
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8986784140969162
============sample only in training=======
4187
7919
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 440
preds.shape: (7919,), labels.shape: (7919,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9523020523101067, f1_test_all: 0.9135967849966511, macro_test: 0.9378416660553792, f1_test: 0.8893709327548808
f1_val_isr: 1.0
f1_test_isr: 0.8893709327548808
============sample only in training=======
4187
7909
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 450
preds.shape: (7909,), labels.shape: (7909,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9522352004197312, f1_test_all: 0.9133964817320703, macro_test: 0.9368114362156108, f1_test: 0.8874316939890711
f1_val_isr: 1.0
f1_test_isr: 0.8874316939890711
============sample only in training=======
4187
7899
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 460
preds.shape: (7899,), labels.shape: (7899,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.951930141575581, f1_test_all: 0.9127147766323024, macro_test: 0.9360745639877662, f1_test: 0.8859357696566997
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8859357696566997
============sample only in training=======
4187
7889
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 470
preds.shape: (7889,), labels.shape: (7889,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9520953414580546, f1_test_all: 0.9129834254143647, macro_test: 0.9374848496558896, f1_test: 0.888646288209607
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.888646288209607
============sample only in training=======
4187
7879
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 480
preds.shape: (7879,), labels.shape: (7879,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9507342833144061, f1_test_all: 0.9104788341429563, macro_test: 0.9359525993730089, f1_test: 0.8859934853420195
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8859934853420195
============sample only in training=======
4187
7869
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 490
preds.shape: (7869,), labels.shape: (7869,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9507962763944962, f1_test_all: 0.9103840682788051, macro_test: 0.9362603517938335, f1_test: 0.8861607142857144
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8861607142857144
============sample only in training=======
4187
7859
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 500
preds.shape: (7859,), labels.shape: (7859,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9501369069924677, f1_test_all: 0.9092198581560285, macro_test: 0.936502140665648, f1_test: 0.8869565217391305
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8869565217391305
============sample only in training=======
4187
7849
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 510
preds.shape: (7849,), labels.shape: (7849,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9490909341279984, f1_test_all: 0.9072753209700427, macro_test: 0.9354040843320608, f1_test: 0.8850325379609545
f1_val_isr: 1.0
f1_test_isr: 0.8850325379609545
============sample only in training=======
4187
7839
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 520
preds.shape: (7839,), labels.shape: (7839,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9509729300273941, f1_test_all: 0.9105454545454545, macro_test: 0.9373158345899457, f1_test: 0.8881506090808416
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8881506090808416
============sample only in training=======
4187
7829
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 530
preds.shape: (7829,), labels.shape: (7829,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9582642661321537, f1_test_all: 0.9239598278335726, macro_test: 0.9438062248383092, f1_test: 0.9001074113856068
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.9001074113856068
============sample only in training=======
4187
7819
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 540
preds.shape: (7819,), labels.shape: (7819,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9580416854483651, f1_test_all: 0.9235209235209235, macro_test: 0.9433800286828805, f1_test: 0.8992416034669555
f1_val_isr: 1.0
f1_test_isr: 0.8992416034669555
============sample only in training=======
4187
7809
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 550
preds.shape: (7809,), labels.shape: (7809,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9593016411414781, f1_test_all: 0.925764192139738, macro_test: 0.9460201243769528, f1_test: 0.9039913700107876
f1_val_isr: 1.0
f1_test_isr: 0.9039913700107876
============sample only in training=======
4187
7799
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 560
preds.shape: (7799,), labels.shape: (7799,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9584438462979334, f1_test_all: 0.924198250728863, macro_test: 0.9450146931213563, f1_test: 0.9022556390977443
f1_val_isr: 1.0
f1_test_isr: 0.9022556390977443
============sample only in training=======
4187
7789
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 570
preds.shape: (7789,), labels.shape: (7789,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9575066538331144, f1_test_all: 0.9223946784922394, macro_test: 0.9437215396411307, f1_test: 0.8997821350762527
f1_val_isr: 1.0
f1_test_isr: 0.8997821350762527
============sample only in training=======
4187
7779
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 580
preds.shape: (7779,), labels.shape: (7779,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9568948284291072, f1_test_all: 0.9212481426448736, macro_test: 0.9435940625511978, f1_test: 0.8996763754045307
f1_val_isr: 1.0
f1_test_isr: 0.8996763754045307
============sample only in training=======
4187
7769
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 590
preds.shape: (7769,), labels.shape: (7769,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9589986054564945, f1_test_all: 0.9250374812593704, macro_test: 0.9469321537662074, f1_test: 0.9055374592833876
f1_val_isr: 1.0
f1_test_isr: 0.9055374592833876
============sample only in training=======
4187
7759
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 600
preds.shape: (7759,), labels.shape: (7759,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9611902522958724, f1_test_all: 0.9290030211480362, macro_test: 0.9507792448106585, f1_test: 0.9124324324324324
f1_val_isr: 1.0
f1_test_isr: 0.9124324324324324
============sample only in training=======
4187
7749
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 610
preds.shape: (7749,), labels.shape: (7749,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9615721844293272, f1_test_all: 0.9297052154195011, macro_test: 0.951524539905712, f1_test: 0.9137931034482759
f1_val_isr: 1.0
f1_test_isr: 0.9137931034482759
============sample only in training=======
4187
7739
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 620
preds.shape: (7739,), labels.shape: (7739,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9593059941647861, f1_test_all: 0.925531914893617, macro_test: 0.948348590233407, f1_test: 0.9081081081081082
f1_val_isr: 1.0
f1_test_isr: 0.9081081081081082
============sample only in training=======
4187
7729
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 630
preds.shape: (7729,), labels.shape: (7729,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9602453536650501, f1_test_all: 0.9272030651340996, macro_test: 0.9499343801402222, f1_test: 0.9108695652173912
f1_val_isr: 1.0
f1_test_isr: 0.9108695652173912
============sample only in training=======
4187
7719
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 640
preds.shape: (7719,), labels.shape: (7719,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.961989167369568, f1_test_all: 0.9303405572755419, macro_test: 0.9526470642821184, f1_test: 0.9157667386609072
f1_val_isr: 1.0
f1_test_isr: 0.9157667386609072
============sample only in training=======
4187
7709
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 650
preds.shape: (7709,), labels.shape: (7709,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.962829448716527, f1_test_all: 0.9318885448916409, macro_test: 0.9529139796976447, f1_test: 0.9163090128755366
f1_val_isr: 1.0
f1_test_isr: 0.9163090128755366
============sample only in training=======
4187
7699
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 660
preds.shape: (7699,), labels.shape: (7699,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9643644005035918, f1_test_all: 0.9346811819595646, macro_test: 0.955244607766665, f1_test: 0.9204301075268818
f1_val_isr: 1.0
f1_test_isr: 0.9204301075268818
============sample only in training=======
4187
7689
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 670
preds.shape: (7689,), labels.shape: (7689,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9622585632828031, f1_test_all: 0.9306772908366534, macro_test: 0.9526711591036441, f1_test: 0.9156626506024096
f1_val_isr: 1.0
f1_test_isr: 0.9156626506024096
============sample only in training=======
4187
7679
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 680
preds.shape: (7679,), labels.shape: (7679,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9631753690573128, f1_test_all: 0.9323786793953859, macro_test: 0.9545113407670949, f1_test: 0.919093851132686
f1_val_isr: 1.0
f1_test_isr: 0.919093851132686
============sample only in training=======
4187
7669
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 690
preds.shape: (7669,), labels.shape: (7669,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9626566189556669, f1_test_all: 0.9314194577352474, macro_test: 0.9532983098542176, f1_test: 0.9169363538295577
f1_val_isr: 1.0
f1_test_isr: 0.9169363538295577
============sample only in training=======
4187
7659
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 700
preds.shape: (7659,), labels.shape: (7659,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9613338045234249, f1_test_all: 0.9289176090468497, macro_test: 0.9521755883294862, f1_test: 0.9149623250807319
f1_val_isr: 1.0
f1_test_isr: 0.9149623250807319
============sample only in training=======
4187
7649
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 710
preds.shape: (7649,), labels.shape: (7649,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9623192300959493, f1_test_all: 0.9307568438003221, macro_test: 0.9537346008140382, f1_test: 0.9178228388473852
f1_val_isr: 1.0
f1_test_isr: 0.9178228388473852
============sample only in training=======
4187
7639
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 720
preds.shape: (7639,), labels.shape: (7639,)
preds.shape: (4187,), labels.shape: (4187,)
macro_test_all: 0.9612105875167971, f1_test_all: 0.9286871961102107, macro_test: 0.9522655028196391, f1_test: 0.9151450053705693
f1_val_isr: 1.0
f1_test_isr: 0.9151450053705693
AL Time: 0.38570398185402155s
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 4187, self.idx_non_test is 4187
finished loading dataset
current seed is 300
len(idx_non_test) is 4187
len(idx_non_test): 4172
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
-------------initial results------------
micro_val: 0.8000, macro_val: 0.6875
strategy:  uncertainty
============sample global=======
4181
8349
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 10
preds.shape: (8349,), labels.shape: (8349,)
preds.shape: (4181,), labels.shape: (4181,)
macro_test_all: 0.8429786155663122, f1_test_all: 0.7173652694610779, macro_test: 0.8399681677059979, f1_test: 0.7103274559193954
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7103274559193954
============sample global=======
4176
8339
macro_val: 0.4444444444444445
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 20
preds.shape: (8339,), labels.shape: (8339,)
preds.shape: (4176,), labels.shape: (4176,)
macro_test_all: 0.6121780585430626, f1_test_all: 0.2836990595611285, macro_test: 0.6189274474790027, f1_test: 0.29324546952224056
f1_val_isr: 0.0
f1_test_isr: 0.29324546952224056
============sample global=======
4173
8329
macro_val: 0.4444444444444445
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 30
preds.shape: (8329,), labels.shape: (8329,)
preds.shape: (4173,), labels.shape: (4173,)
macro_test_all: 0.6490244827440901, f1_test_all: 0.3506805444355484, macro_test: 0.6519998749100916, f1_test: 0.35353535353535354
f1_val_isr: 0.0
f1_test_isr: 0.35353535353535354
============sample global=======
4168
8319
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 40
preds.shape: (8319,), labels.shape: (8319,)
preds.shape: (4168,), labels.shape: (4168,)
macro_test_all: 0.766486638977805, f1_test_all: 0.5750500333555704, macro_test: 0.7674013567302465, f1_test: 0.5742574257425743
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.5742574257425743
============sample global=======
4163
8309
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 50
preds.shape: (8309,), labels.shape: (8309,)
preds.shape: (4163,), labels.shape: (4163,)
macro_test_all: 0.8235906603164328, f1_test_all: 0.6800258564964446, macro_test: 0.8264687439878582, f1_test: 0.6837837837837838
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.6837837837837838
============sample global=======
4159
8299
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 60
preds.shape: (8299,), labels.shape: (8299,)
preds.shape: (4159,), labels.shape: (4159,)
macro_test_all: 0.8212682164708737, f1_test_all: 0.6757457846952011, macro_test: 0.8198019944974402, f1_test: 0.6712328767123288
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.6712328767123288
============sample global=======
4156
8289
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 70
preds.shape: (8289,), labels.shape: (8289,)
preds.shape: (4156,), labels.shape: (4156,)
macro_test_all: 0.8396903476447568, f1_test_all: 0.7098412698412698, macro_test: 0.8409534966291276, f1_test: 0.710455764075067
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.710455764075067
============sample global=======
4152
8279
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 80
preds.shape: (8279,), labels.shape: (8279,)
preds.shape: (4152,), labels.shape: (4152,)
macro_test_all: 0.8320806832595018, f1_test_all: 0.6959847036328872, macro_test: 0.8347848383966048, f1_test: 0.6990553306342778
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.6990553306342778
============sample global=======
4147
8269
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 90
preds.shape: (8269,), labels.shape: (8269,)
preds.shape: (4147,), labels.shape: (4147,)
macro_test_all: 0.817607472430997, f1_test_all: 0.6688524590163935, macro_test: 0.8204477557134096, f1_test: 0.6721991701244814
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.6721991701244814
============sample global=======
4142
8259
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 100
preds.shape: (8259,), labels.shape: (8259,)
preds.shape: (4142,), labels.shape: (4142,)
macro_test_all: 0.8269212633902532, f1_test_all: 0.6858638743455499, macro_test: 0.8289755619866117, f1_test: 0.6878453038674033
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.6878453038674033
============sample global=======
4138
8249
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 110
preds.shape: (8249,), labels.shape: (8249,)
preds.shape: (4138,), labels.shape: (4138,)
macro_test_all: 0.8338493842146234, f1_test_all: 0.698495748855461, macro_test: 0.8374876129674536, f1_test: 0.703448275862069
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.703448275862069
============sample global=======
4134
8239
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 120
preds.shape: (8239,), labels.shape: (8239,)
preds.shape: (4134,), labels.shape: (4134,)
macro_test_all: 0.8381542809100101, f1_test_all: 0.7063440156965337, macro_test: 0.84009745125375, f1_test: 0.7081604426002766
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7081604426002766
============sample global=======
4130
8229
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 130
preds.shape: (8229,), labels.shape: (8229,)
preds.shape: (4130,), labels.shape: (4130,)
macro_test_all: 0.8404844355309491, f1_test_all: 0.7106466361854997, macro_test: 0.8391235101340648, f1_test: 0.7063711911357339
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7063711911357339
============sample global=======
4126
8219
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 140
preds.shape: (8219,), labels.shape: (8219,)
preds.shape: (4126,), labels.shape: (4126,)
macro_test_all: 0.8439684945915996, f1_test_all: 0.7169069462647444, macro_test: 0.8427061810720036, f1_test: 0.7128987517337031
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7128987517337031
============sample global=======
4120
8209
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 150
preds.shape: (8209,), labels.shape: (8209,)
preds.shape: (4120,), labels.shape: (4120,)
macro_test_all: 0.8468402436975533, f1_test_all: 0.7220026350461133, macro_test: 0.8445535859489348, f1_test: 0.7160839160839161
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7160839160839161
============sample global=======
4114
8199
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 160
preds.shape: (8199,), labels.shape: (8199,)
preds.shape: (4114,), labels.shape: (4114,)
macro_test_all: 0.8491053569229923, f1_test_all: 0.7259455872594558, macro_test: 0.8479717860029627, f1_test: 0.7221438645980254
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7221438645980254
============sample global=======
4109
8189
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 170
preds.shape: (8189,), labels.shape: (8189,)
preds.shape: (4109,), labels.shape: (4109,)
macro_test_all: 0.8502348992115992, f1_test_all: 0.7275185936443542, macro_test: 0.8500938557509305, f1_test: 0.7254335260115607
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7254335260115607
============sample global=======
4102
8179
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 180
preds.shape: (8179,), labels.shape: (8179,)
preds.shape: (4102,), labels.shape: (4102,)
macro_test_all: 0.8523687662199617, f1_test_all: 0.7313432835820897, macro_test: 0.8528404948444064, f1_test: 0.7304347826086957
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7304347826086957
============sample global=======
4098
8169
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 190
preds.shape: (8169,), labels.shape: (8169,)
preds.shape: (4098,), labels.shape: (4098,)
macro_test_all: 0.8598631053471257, f1_test_all: 0.7450980392156862, macro_test: 0.8608634436271807, f1_test: 0.7453237410071942
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7453237410071942
============sample global=======
4091
8159
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 200
preds.shape: (8159,), labels.shape: (8159,)
preds.shape: (4091,), labels.shape: (4091,)
macro_test_all: 0.863519819144887, f1_test_all: 0.7516960651289009, macro_test: 0.8683596933029434, f1_test: 0.759018759018759
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.759018759018759
============sample global=======
4088
8149
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 210
preds.shape: (8149,), labels.shape: (8149,)
preds.shape: (4088,), labels.shape: (4088,)
macro_test_all: 0.8644980073898368, f1_test_all: 0.7534059945504087, macro_test: 0.8677355913558535, f1_test: 0.7579250720461095
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7579250720461095
============sample global=======
4085
8139
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 220
preds.shape: (8139,), labels.shape: (8139,)
preds.shape: (4085,), labels.shape: (4085,)
macro_test_all: 0.8674438835406559, f1_test_all: 0.758714969241285, macro_test: 0.8705373913769408, f1_test: 0.7630057803468208
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7630057803468208
============sample global=======
4083
8129
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 230
preds.shape: (8129,), labels.shape: (8129,)
preds.shape: (4083,), labels.shape: (4083,)
macro_test_all: 0.8786845158839094, f1_test_all: 0.7795010114632501, macro_test: 0.879373615383545, f1_test: 0.7795163584637268
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7795163584637268
============sample global=======
4080
8119
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 240
preds.shape: (8119,), labels.shape: (8119,)
preds.shape: (4080,), labels.shape: (4080,)
macro_test_all: 0.8891847098082819, f1_test_all: 0.7989382879893829, macro_test: 0.8876706211757324, f1_test: 0.7949438202247192
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.7949438202247192
============sample global=======
4074
8109
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 250
preds.shape: (8109,), labels.shape: (8109,)
preds.shape: (4074,), labels.shape: (4074,)
macro_test_all: 0.9079485083776053, f1_test_all: 0.8333333333333334, macro_test: 0.9077591524861313, f1_test: 0.8319559228650137
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8319559228650137
============sample global=======
4070
8099
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 260
preds.shape: (8099,), labels.shape: (8099,)
preds.shape: (4070,), labels.shape: (4070,)
macro_test_all: 0.9163541583694224, f1_test_all: 0.8486029889538661, macro_test: 0.9137994457659956, f1_test: 0.8429752066115703
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8429752066115703
============sample global=======
4065
8089
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 270
preds.shape: (8089,), labels.shape: (8089,)
preds.shape: (4065,), labels.shape: (4065,)
macro_test_all: 0.9114109358849061, f1_test_all: 0.8393919365499009, macro_test: 0.9085276782555372, f1_test: 0.8330995792426368
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8330995792426368
============sample global=======
4063
8079
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 280
preds.shape: (8079,), labels.shape: (8079,)
preds.shape: (4063,), labels.shape: (4063,)
macro_test_all: 0.9148437927286442, f1_test_all: 0.8455931080185554, macro_test: 0.9126987537602063, f1_test: 0.840782122905028
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.840782122905028
============sample global=======
4057
8069
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 290
preds.shape: (8069,), labels.shape: (8069,)
preds.shape: (4057,), labels.shape: (4057,)
macro_test_all: 0.918196314352277, f1_test_all: 0.8516300731869593, macro_test: 0.9164103635248384, f1_test: 0.8475524475524475
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8475524475524475
============sample global=======
4050
8059
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 300
preds.shape: (8059,), labels.shape: (8059,)
preds.shape: (4050,), labels.shape: (4050,)
macro_test_all: 0.9184323881818859, f1_test_all: 0.8519758874748827, macro_test: 0.9164236187541273, f1_test: 0.847457627118644
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.847457627118644
============sample global=======
4046
8049
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 310
preds.shape: (8049,), labels.shape: (8049,)
preds.shape: (4046,), labels.shape: (4046,)
macro_test_all: 0.9180274655125815, f1_test_all: 0.8511784511784511, macro_test: 0.9162016187120723, f1_test: 0.8470254957507083
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8470254957507083
============sample global=======
4039
8039
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 320
preds.shape: (8039,), labels.shape: (8039,)
preds.shape: (4039,), labels.shape: (4039,)
macro_test_all: 0.9199522358385805, f1_test_all: 0.854631507775524, macro_test: 0.9182014128312077, f1_test: 0.8506401137980086
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8506401137980086
============sample global=======
4033
8029
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 330
preds.shape: (8029,), labels.shape: (8029,)
preds.shape: (4033,), labels.shape: (4033,)
macro_test_all: 0.9199739811552471, f1_test_all: 0.8546195652173912, macro_test: 0.9168754997215558, f1_test: 0.8481375358166188
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8481375358166188
============sample global=======
4027
8019
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 340
preds.shape: (8019,), labels.shape: (8019,)
preds.shape: (4027,), labels.shape: (4027,)
macro_test_all: 0.9207469327656995, f1_test_all: 0.8559726962457338, macro_test: 0.9177921933126365, f1_test: 0.8497109826589595
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8497109826589595
============sample global=======
4023
8009
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 350
preds.shape: (8009,), labels.shape: (8009,)
preds.shape: (4023,), labels.shape: (4023,)
macro_test_all: 0.9286004970411604, f1_test_all: 0.8703326544467074, macro_test: 0.9255805557843527, f1_test: 0.8640915593705294
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8640915593705294
============sample global=======
4018
7999
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 360
preds.shape: (7999,), labels.shape: (7999,)
preds.shape: (4018,), labels.shape: (4018,)
macro_test_all: 0.9329960943351364, f1_test_all: 0.8783140720598233, macro_test: 0.9260679946130478, f1_test: 0.8649425287356323
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8649425287356323
============sample global=======
4015
7989
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 370
preds.shape: (7989,), labels.shape: (7989,)
preds.shape: (4015,), labels.shape: (4015,)
macro_test_all: 0.9316537141177734, f1_test_all: 0.8757721345229924, macro_test: 0.9265626926796342, f1_test: 0.8658008658008659
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8658008658008659
============sample global=======
4011
7979
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 380
preds.shape: (7979,), labels.shape: (7979,)
preds.shape: (4011,), labels.shape: (4011,)
macro_test_all: 0.9329113716023908, f1_test_all: 0.8779472954230235, macro_test: 0.9275668789050524, f1_test: 0.8675400291120815
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8675400291120815
============sample global=======
4006
7969
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 390
preds.shape: (7969,), labels.shape: (7969,)
preds.shape: (4006,), labels.shape: (4006,)
macro_test_all: 0.9333321986489949, f1_test_all: 0.8786610878661087, macro_test: 0.9280696966214663, f1_test: 0.868421052631579
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.868421052631579
============sample global=======
4002
7959
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 400
preds.shape: (7959,), labels.shape: (7959,)
preds.shape: (4002,), labels.shape: (4002,)
macro_test_all: 0.936812377168859, f1_test_all: 0.8850174216027875, macro_test: 0.9310774342538977, f1_test: 0.8739002932551321
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8739002932551321
============sample global=======
3999
7949
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 410
preds.shape: (7949,), labels.shape: (7949,)
preds.shape: (3999,), labels.shape: (3999,)
macro_test_all: 0.9366701915853546, f1_test_all: 0.8846694796061885, macro_test: 0.9308887834991881, f1_test: 0.8735294117647059
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8735294117647059
============sample global=======
3995
7939
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 420
preds.shape: (7939,), labels.shape: (7939,)
preds.shape: (3995,), labels.shape: (3995,)
macro_test_all: 0.9360944666080291, f1_test_all: 0.8835227272727273, macro_test: 0.9303242517112202, f1_test: 0.8724035608308606
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8724035608308606
============sample global=======
3990
7929
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 430
preds.shape: (7929,), labels.shape: (7929,)
preds.shape: (3990,), labels.shape: (3990,)
macro_test_all: 0.937485142964595, f1_test_all: 0.886039886039886, macro_test: 0.9317528735632183, f1_test: 0.8750000000000001
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8750000000000001
============sample global=======
3985
7919
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 440
preds.shape: (7919,), labels.shape: (7919,)
preds.shape: (3985,), labels.shape: (3985,)
macro_test_all: 0.9406506903792117, f1_test_all: 0.8917562724014337, macro_test: 0.9346418092328082, f1_test: 0.8802395209580839
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8802395209580839
============sample global=======
3980
7909
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 450
preds.shape: (7909,), labels.shape: (7909,)
preds.shape: (3980,), labels.shape: (3980,)
macro_test_all: 0.9457184582367504, f1_test_all: 0.9010043041606888, macro_test: 0.9411708672616369, f1_test: 0.8922155688622755
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8922155688622755
============sample global=======
3975
7899
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 460
preds.shape: (7899,), labels.shape: (7899,)
preds.shape: (3975,), labels.shape: (3975,)
macro_test_all: 0.9512193129837598, f1_test_all: 0.9110473457675753, macro_test: 0.9451753595946775, f1_test: 0.8995502248875562
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.8995502248875562
============sample global=======
3969
7889
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 470
preds.shape: (7889,), labels.shape: (7889,)
preds.shape: (3969,), labels.shape: (3969,)
macro_test_all: 0.9516237827761289, f1_test_all: 0.9117221418234442, macro_test: 0.9454657873042045, f1_test: 0.9
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.9
============sample global=======
3964
7879
macro_val: 0.803921568627451
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.6666666666666666
the number of labels is 480
preds.shape: (7879,), labels.shape: (7879,)
preds.shape: (3964,), labels.shape: (3964,)
macro_test_all: 0.9533258348288572, f1_test_all: 0.9147851420247634, macro_test: 0.9468190721511176, f1_test: 0.9024390243902438
f1_val_isr: 0.6666666666666666
f1_test_isr: 0.9024390243902438
============sample global=======
3958
7869
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 490
preds.shape: (7869,), labels.shape: (7869,)
preds.shape: (3958,), labels.shape: (3958,)
macro_test_all: 0.9566537741041886, f1_test_all: 0.9208211143695014, macro_test: 0.9522982800562003, f1_test: 0.9124423963133641
f1_val_isr: 1.0
f1_test_isr: 0.9124423963133641
============sample global=======
3952
7859
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 500
preds.shape: (7859,), labels.shape: (7859,)
preds.shape: (3952,), labels.shape: (3952,)
macro_test_all: 0.9593233657620439, f1_test_all: 0.925680647534952, macro_test: 0.9562933017545292, f1_test: 0.9197530864197531
f1_val_isr: 1.0
f1_test_isr: 0.9197530864197531
============sample global=======
3946
7849
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 510
preds.shape: (7849,), labels.shape: (7849,)
preds.shape: (3946,), labels.shape: (3946,)
macro_test_all: 0.9592097460401501, f1_test_all: 0.925461254612546, macro_test: 0.9560401327245555, f1_test: 0.9192546583850931
f1_val_isr: 1.0
f1_test_isr: 0.9192546583850931
============sample global=======
3942
7839
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 520
preds.shape: (7839,), labels.shape: (7839,)
preds.shape: (3942,), labels.shape: (3942,)
macro_test_all: 0.9608204799495458, f1_test_all: 0.9284132841328414, macro_test: 0.9577270855495694, f1_test: 0.922360248447205
f1_val_isr: 1.0
f1_test_isr: 0.922360248447205
============sample global=======
3937
7829
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 530
preds.shape: (7829,), labels.shape: (7829,)
preds.shape: (3937,), labels.shape: (3937,)
macro_test_all: 0.9639026711145784, f1_test_all: 0.9340252038547072, macro_test: 0.9609941450941472, f1_test: 0.9283489096573209
f1_val_isr: 1.0
f1_test_isr: 0.9283489096573209
============sample global=======
3932
7819
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 540
preds.shape: (7819,), labels.shape: (7819,)
preds.shape: (3932,), labels.shape: (3932,)
macro_test_all: 0.9691508867814433, f1_test_all: 0.943620178041543, macro_test: 0.9669729489093823, f1_test: 0.9393468118195956
f1_val_isr: 1.0
f1_test_isr: 0.9393468118195956
============sample global=======
3928
7809
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 550
preds.shape: (7809,), labels.shape: (7809,)
preds.shape: (3928,), labels.shape: (3928,)
macro_test_all: 0.9704931908170811, f1_test_all: 0.9460269865067468, macro_test: 0.9666865499489725, f1_test: 0.9387755102040817
f1_val_isr: 1.0
f1_test_isr: 0.9387755102040817
============sample global=======
3921
7799
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 560
preds.shape: (7799,), labels.shape: (7799,)
preds.shape: (3921,), labels.shape: (3921,)
macro_test_all: 0.970879733603222, f1_test_all: 0.9467366841710427, macro_test: 0.9674890945176713, f1_test: 0.940251572327044
f1_val_isr: 1.0
f1_test_isr: 0.940251572327044
============sample global=======
3916
7789
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 570
preds.shape: (7789,), labels.shape: (7789,)
preds.shape: (3916,), labels.shape: (3916,)
macro_test_all: 0.9710698555567441, f1_test_all: 0.9470499243570347, macro_test: 0.9672031137735109, f1_test: 0.9396825396825396
f1_val_isr: 1.0
f1_test_isr: 0.9396825396825396
============sample global=======
3911
7779
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 580
preds.shape: (7779,), labels.shape: (7779,)
preds.shape: (3911,), labels.shape: (3911,)
macro_test_all: 0.9717768285848313, f1_test_all: 0.9483282674772037, macro_test: 0.9671041331328832, f1_test: 0.9394904458598726
f1_val_isr: 1.0
f1_test_isr: 0.9394904458598726
============sample global=======
3907
7769
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 590
preds.shape: (7769,), labels.shape: (7769,)
preds.shape: (3907,), labels.shape: (3907,)
macro_test_all: 0.9717734713845025, f1_test_all: 0.9483282674772037, macro_test: 0.9671011928714893, f1_test: 0.9394904458598726
f1_val_isr: 1.0
f1_test_isr: 0.9394904458598726
============sample global=======
3901
7759
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 600
preds.shape: (7759,), labels.shape: (7759,)
preds.shape: (3901,), labels.shape: (3901,)
macro_test_all: 0.9715343724885428, f1_test_all: 0.9478527607361962, macro_test: 0.9667093360641748, f1_test: 0.9387096774193547
f1_val_isr: 1.0
f1_test_isr: 0.9387096774193547
============sample global=======
3897
7749
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 610
preds.shape: (7749,), labels.shape: (7749,)
preds.shape: (3897,), labels.shape: (3897,)
macro_test_all: 0.9727299999561458, f1_test_all: 0.9500384319754036, macro_test: 0.9675346884094274, f1_test: 0.9402261712439418
f1_val_isr: 1.0
f1_test_isr: 0.9402261712439418
============sample global=======
3893
7739
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 620
preds.shape: (7739,), labels.shape: (7739,)
preds.shape: (3893,), labels.shape: (3893,)
macro_test_all: 0.9726119991931175, f1_test_all: 0.9498069498069498, macro_test: 0.9674356522873446, f1_test: 0.9400324149108589
f1_val_isr: 1.0
f1_test_isr: 0.9400324149108589
============sample global=======
3886
7729
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 630
preds.shape: (7729,), labels.shape: (7729,)
preds.shape: (3886,), labels.shape: (3886,)
macro_test_all: 0.9729351874953492, f1_test_all: 0.9503875968992248, macro_test: 0.9681693701860199, f1_test: 0.9413680781758956
f1_val_isr: 1.0
f1_test_isr: 0.9413680781758956
============sample global=======
3882
7719
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 640
preds.shape: (7719,), labels.shape: (7719,)
preds.shape: (3882,), labels.shape: (3882,)
macro_test_all: 0.9730315114009531, f1_test_all: 0.9505106048703849, macro_test: 0.9687245283991732, f1_test: 0.9423393739703458
f1_val_isr: 1.0
f1_test_isr: 0.9423393739703458
============sample global=======
3876
7709
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 650
preds.shape: (7709,), labels.shape: (7709,)
preds.shape: (3876,), labels.shape: (3876,)
macro_test_all: 0.9746319951842003, f1_test_all: 0.9534333070244673, macro_test: 0.9704186117506393, f1_test: 0.9454545454545455
f1_val_isr: 1.0
f1_test_isr: 0.9454545454545455
============sample global=======
3869
7699
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 660
preds.shape: (7699,), labels.shape: (7699,)
preds.shape: (3869,), labels.shape: (3869,)
macro_test_all: 0.9754890770916428, f1_test_all: 0.9550118389897394, macro_test: 0.9722071665509975, f1_test: 0.9487603305785124
f1_val_isr: 1.0
f1_test_isr: 0.9487603305785124
============sample global=======
3862
7689
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 670
preds.shape: (7689,), labels.shape: (7689,)
preds.shape: (3862,), labels.shape: (3862,)
macro_test_all: 0.9774255093979639, f1_test_all: 0.9585326953748006, macro_test: 0.9745459818166753, f1_test: 0.953020134228188
f1_val_isr: 1.0
f1_test_isr: 0.953020134228188
============sample global=======
3856
7679
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 680
preds.shape: (7679,), labels.shape: (7679,)
preds.shape: (3856,), labels.shape: (3856,)
macro_test_all: 0.9790069562182449, f1_test_all: 0.9614147909967845, macro_test: 0.9762146978439115, f1_test: 0.9560810810810811
f1_val_isr: 1.0
f1_test_isr: 0.9560810810810811
============sample global=======
3855
7669
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 690
preds.shape: (7669,), labels.shape: (7669,)
preds.shape: (3855,), labels.shape: (3855,)
macro_test_all: 0.9800977061021072, f1_test_all: 0.9633848657445078, macro_test: 0.9762141848226422, f1_test: 0.9560810810810811
f1_val_isr: 1.0
f1_test_isr: 0.9560810810810811
============sample global=======
3848
7659
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 700
preds.shape: (7659,), labels.shape: (7659,)
preds.shape: (3848,), labels.shape: (3848,)
macro_test_all: 0.9805232994962584, f1_test_all: 0.964169381107492, macro_test: 0.977090083363995, f1_test: 0.9576988155668358
f1_val_isr: 1.0
f1_test_isr: 0.9576988155668358
============sample global=======
3844
7649
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 710
preds.shape: (7649,), labels.shape: (7649,)
preds.shape: (3844,), labels.shape: (3844,)
macro_test_all: 0.9816443036200245, f1_test_all: 0.966199505358615, macro_test: 0.9767998522529613, f1_test: 0.9571183533447684
f1_val_isr: 1.0
f1_test_isr: 0.9571183533447684
============sample global=======
3839
7639
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 720
preds.shape: (7639,), labels.shape: (7639,)
preds.shape: (3839,), labels.shape: (3839,)
macro_test_all: 0.9818573391682448, f1_test_all: 0.9665551839464883, macro_test: 0.9764256668545737, f1_test: 0.956369982547993
f1_val_isr: 1.0
f1_test_isr: 0.956369982547993
AL Time: 0.4485289570875466s
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 5862, self.idx_non_test is 2512
finished loading dataset
current seed is 300
len(idx_non_test) is 2512
len(idx_non_test): 2497
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
-------------initial results------------
micro_val: 0.7000, macro_val: 0.4118
strategy:  uncertainty
============sample only in training=======
5862
8349
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 10
preds.shape: (8349,), labels.shape: (8349,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.4687579536777806, f1_test_all: 0.0, macro_test: 0.4701735357917571, f1_test: 0.0
f1_val_isr: 0.0
f1_test_isr: 0.0
============sample only in training=======
5862
8339
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 20
preds.shape: (8339,), labels.shape: (8339,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.4687181447502548, f1_test_all: 0.0, macro_test: 0.4701735357917571, f1_test: 0.0
f1_val_isr: 0.0
f1_test_isr: 0.0
============sample only in training=======
5862
8329
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 30
preds.shape: (8329,), labels.shape: (8329,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.5711473078557652, f1_test_all: 0.21685082872928177, macro_test: 0.576424722660672, f1_test: 0.22532402791625125
f1_val_isr: 0.5
f1_test_isr: 0.22532402791625125
============sample only in training=======
5862
8319
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 40
preds.shape: (8319,), labels.shape: (8319,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.7172877257613943, f1_test_all: 0.4870466321243523, macro_test: 0.7175620332450012, f1_test: 0.48571428571428565
f1_val_isr: 0.5
f1_test_isr: 0.48571428571428565
============sample only in training=======
5862
8309
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 50
preds.shape: (8309,), labels.shape: (8309,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.7540248041262205, f1_test_all: 0.5542014111610007, macro_test: 0.7512707928554385, f1_test: 0.5473484848484848
f1_val_isr: 0.5
f1_test_isr: 0.5473484848484848
============sample only in training=======
5862
8299
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 60
preds.shape: (8299,), labels.shape: (8299,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.7772705559049045, f1_test_all: 0.5955497382198952, macro_test: 0.7764195570886621, f1_test: 0.5927342256214149
f1_val_isr: 0.5
f1_test_isr: 0.5927342256214149
============sample only in training=======
5862
8289
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 70
preds.shape: (8289,), labels.shape: (8289,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.7957368615132691, f1_test_all: 0.6282652377762894, macro_test: 0.7974125407966977, f1_test: 0.6304558680892337
f1_val_isr: 0.5
f1_test_isr: 0.6304558680892337
============sample only in training=======
5862
8279
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 80
preds.shape: (8279,), labels.shape: (8279,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8229086853199512, f1_test_all: 0.6787800129785854, macro_test: 0.8271435425207614, f1_test: 0.6859273066169618
f1_val_isr: 0.8
f1_test_isr: 0.6859273066169618
============sample only in training=======
5862
8269
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 90
preds.shape: (8269,), labels.shape: (8269,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8354391202001975, f1_test_all: 0.7022222222222223, macro_test: 0.8411195080542169, f1_test: 0.7120799273387829
f1_val_isr: 0.8
f1_test_isr: 0.7120799273387829
============sample only in training=======
5862
8259
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 100
preds.shape: (8259,), labels.shape: (8259,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8446281933025047, f1_test_all: 0.7188295165394402, macro_test: 0.8500061409972979, f1_test: 0.7282608695652173
f1_val_isr: 0.8
f1_test_isr: 0.7282608695652173
============sample only in training=======
5862
8249
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 110
preds.shape: (8249,), labels.shape: (8249,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8506699635068753, f1_test_all: 0.7298156389065479, macro_test: 0.853809714824582, f1_test: 0.7354260089686099
f1_val_isr: 0.8
f1_test_isr: 0.7354260089686099
============sample only in training=======
5862
8239
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 120
preds.shape: (8239,), labels.shape: (8239,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8538966198579848, f1_test_all: 0.735705209656925, macro_test: 0.8554962690023518, f1_test: 0.7386262265834077
f1_val_isr: 0.8
f1_test_isr: 0.7386262265834077
============sample only in training=======
5862
8229
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 130
preds.shape: (8229,), labels.shape: (8229,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8552828873658109, f1_test_all: 0.7382465057179161, macro_test: 0.8583721201445774, f1_test: 0.7440212577502213
f1_val_isr: 0.8
f1_test_isr: 0.7440212577502213
============sample only in training=======
5862
8219
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 140
preds.shape: (8219,), labels.shape: (8219,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8573179637540704, f1_test_all: 0.7418738049713194, macro_test: 0.8596391343907799, f1_test: 0.7464788732394366
f1_val_isr: 0.8
f1_test_isr: 0.7464788732394366
============sample only in training=======
5862
8209
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 150
preds.shape: (8209,), labels.shape: (8209,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.855350417672095, f1_test_all: 0.7383831954169319, macro_test: 0.8580518246559168, f1_test: 0.7439024390243903
f1_val_isr: 0.8
f1_test_isr: 0.7439024390243903
============sample only in training=======
5862
8199
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 160
preds.shape: (8199,), labels.shape: (8199,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8559662552970086, f1_test_all: 0.739214423696072, macro_test: 0.8593272586267333, f1_test: 0.7460595446584939
f1_val_isr: 0.8
f1_test_isr: 0.7460595446584939
============sample only in training=======
5862
8189
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 170
preds.shape: (8189,), labels.shape: (8189,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8630200082843327, f1_test_all: 0.752234993614304, macro_test: 0.8648936514521601, f1_test: 0.7564766839378239
f1_val_isr: 0.8
f1_test_isr: 0.7564766839378239
============sample only in training=======
5862
8179
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 180
preds.shape: (8179,), labels.shape: (8179,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8671900745645161, f1_test_all: 0.76010101010101, macro_test: 0.8686248674668957, f1_test: 0.7636054421768707
f1_val_isr: 0.8
f1_test_isr: 0.7636054421768707
============sample only in training=======
5862
8169
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 190
preds.shape: (8169,), labels.shape: (8169,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8745938220925499, f1_test_all: 0.77375, macro_test: 0.872264189078231, f1_test: 0.7707641196013288
f1_val_isr: 0.8
f1_test_isr: 0.7707641196013288
============sample only in training=======
5862
8159
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 200
preds.shape: (8159,), labels.shape: (8159,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8783420947632975, f1_test_all: 0.7803030303030304, macro_test: 0.8752348681760885, f1_test: 0.7758186397984886
f1_val_isr: 0.8
f1_test_isr: 0.7758186397984886
============sample only in training=======
5862
8149
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 210
preds.shape: (8149,), labels.shape: (8149,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8801655114716311, f1_test_all: 0.7834920634920635, macro_test: 0.8772867364885995, f1_test: 0.779547359597653
f1_val_isr: 0.8
f1_test_isr: 0.779547359597653
============sample only in training=======
5862
8139
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 220
preds.shape: (8139,), labels.shape: (8139,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8794659218803913, f1_test_all: 0.7821086261980831, macro_test: 0.8770941131024388, f1_test: 0.7792642140468228
f1_val_isr: 0.8
f1_test_isr: 0.7792642140468228
============sample only in training=======
5862
8129
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 230
preds.shape: (8129,), labels.shape: (8129,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8834260736534194, f1_test_all: 0.789237668161435, macro_test: 0.8817221513036391, f1_test: 0.7876769358867611
f1_val_isr: 0.8
f1_test_isr: 0.7876769358867611
============sample only in training=======
5862
8119
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 240
preds.shape: (8119,), labels.shape: (8119,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.8982721855172905, f1_test_all: 0.8164037854889589, macro_test: 0.8955454220065358, f1_test: 0.8130081300813008
f1_val_isr: 1.0
f1_test_isr: 0.8130081300813008
============sample only in training=======
5862
8109
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 250
preds.shape: (8109,), labels.shape: (8109,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9128245145996374, f1_test_all: 0.8428927680798005, macro_test: 0.9105713018203953, f1_test: 0.8403494837172358
f1_val_isr: 1.0
f1_test_isr: 0.8403494837172358
============sample only in training=======
5862
8099
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 260
preds.shape: (8099,), labels.shape: (8099,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9202993596961979, f1_test_all: 0.8564325668116843, macro_test: 0.9190941735035307, f1_test: 0.8557993730407523
f1_val_isr: 1.0
f1_test_isr: 0.8557993730407523
============sample only in training=======
5862
8089
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 270
preds.shape: (8089,), labels.shape: (8089,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9230018181051727, f1_test_all: 0.8613861386138614, macro_test: 0.9207358768961935, f1_test: 0.8589147286821706
f1_val_isr: 1.0
f1_test_isr: 0.8589147286821706
============sample only in training=======
5862
8079
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 280
preds.shape: (8079,), labels.shape: (8079,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9249979369816667, f1_test_all: 0.8648310387984981, macro_test: 0.9238055482763268, f1_test: 0.8642745709828392
f1_val_isr: 1.0
f1_test_isr: 0.8642745709828392
============sample only in training=======
5862
8069
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 290
preds.shape: (8069,), labels.shape: (8069,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9258474547157275, f1_test_all: 0.8664169787765293, macro_test: 0.924042366270768, f1_test: 0.8648648648648649
f1_val_isr: 1.0
f1_test_isr: 0.8648648648648649
============sample only in training=======
5862
8059
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 300
preds.shape: (8059,), labels.shape: (8059,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.928049757212126, f1_test_all: 0.8702770780856424, macro_test: 0.9265334622408421, f1_test: 0.8691588785046728
f1_val_isr: 1.0
f1_test_isr: 0.8691588785046728
============sample only in training=======
5862
8049
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 310
preds.shape: (8049,), labels.shape: (8049,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.930373209571463, f1_test_all: 0.8747686613201727, macro_test: 0.9270575227855646, f1_test: 0.8705526116578349
f1_val_isr: 1.0
f1_test_isr: 0.8705526116578349
============sample only in training=======
5862
8039
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 320
preds.shape: (8039,), labels.shape: (8039,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.931355018965108, f1_test_all: 0.8765432098765433, macro_test: 0.9285731070802861, f1_test: 0.8733031674208146
f1_val_isr: 1.0
f1_test_isr: 0.8733031674208146
============sample only in training=======
5862
8029
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 330
preds.shape: (8029,), labels.shape: (8029,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9313538797311329, f1_test_all: 0.8764044943820225, macro_test: 0.9285758325230062, f1_test: 0.8730886850152904
f1_val_isr: 1.0
f1_test_isr: 0.8730886850152904
============sample only in training=======
5862
8019
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 340
preds.shape: (8019,), labels.shape: (8019,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.932656617952625, f1_test_all: 0.87875, macro_test: 0.9306673730051, f1_test: 0.8768996960486322
f1_val_isr: 1.0
f1_test_isr: 0.8768996960486322
============sample only in training=======
5862
8009
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 350
preds.shape: (8009,), labels.shape: (8009,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9342918388258439, f1_test_all: 0.8816120906801007, macro_test: 0.9324933517246641, f1_test: 0.880061115355233
f1_val_isr: 1.0
f1_test_isr: 0.880061115355233
============sample only in training=======
5862
7999
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 360
preds.shape: (7999,), labels.shape: (7999,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9325630127937701, f1_test_all: 0.8785982478097623, macro_test: 0.9306532739904236, f1_test: 0.8769811320754717
f1_val_isr: 1.0
f1_test_isr: 0.8769811320754717
============sample only in training=======
5862
7989
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 370
preds.shape: (7989,), labels.shape: (7989,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9331874744756852, f1_test_all: 0.8796471329552615, macro_test: 0.9314322810434295, f1_test: 0.878234398782344
f1_val_isr: 1.0
f1_test_isr: 0.878234398782344
============sample only in training=======
5862
7979
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 380
preds.shape: (7979,), labels.shape: (7979,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9314529109786784, f1_test_all: 0.876780185758514, macro_test: 0.9293159288359052, f1_test: 0.8748137108792847
f1_val_isr: 1.0
f1_test_isr: 0.8748137108792847
============sample only in training=======
5862
7969
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 390
preds.shape: (7969,), labels.shape: (7969,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9330685989232345, f1_test_all: 0.8796007485963817, macro_test: 0.9313947319143625, f1_test: 0.8783783783783784
f1_val_isr: 1.0
f1_test_isr: 0.8783783783783784
============sample only in training=======
5862
7959
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 400
preds.shape: (7959,), labels.shape: (7959,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9327610172559337, f1_test_all: 0.8789968652037617, macro_test: 0.9310332907273995, f1_test: 0.877643504531722
f1_val_isr: 1.0
f1_test_isr: 0.877643504531722
============sample only in training=======
5862
7949
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 410
preds.shape: (7949,), labels.shape: (7949,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9338666794117438, f1_test_all: 0.8808618504435994, macro_test: 0.9324030322689965, f1_test: 0.8798775822494261
f1_val_isr: 1.0
f1_test_isr: 0.8798775822494261
============sample only in training=======
5862
7939
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 420
preds.shape: (7939,), labels.shape: (7939,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9340626353351567, f1_test_all: 0.8813559322033899, macro_test: 0.932736172437834, f1_test: 0.8806646525679758
f1_val_isr: 1.0
f1_test_isr: 0.8806646525679758
============sample only in training=======
5862
7929
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 430
preds.shape: (7929,), labels.shape: (7929,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9325070685124504, f1_test_all: 0.8785399622404028, macro_test: 0.9300896691285656, f1_test: 0.8759455370650528
f1_val_isr: 1.0
f1_test_isr: 0.8759455370650528
============sample only in training=======
5862
7919
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 440
preds.shape: (7919,), labels.shape: (7919,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9300101639489151, f1_test_all: 0.8740554156171284, macro_test: 0.9272497536954751, f1_test: 0.8709433962264151
f1_val_isr: 1.0
f1_test_isr: 0.8709433962264151
============sample only in training=======
5862
7909
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 450
preds.shape: (7909,), labels.shape: (7909,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9317120867819779, f1_test_all: 0.8771266540642721, macro_test: 0.929330409016965, f1_test: 0.8746223564954682
f1_val_isr: 1.0
f1_test_isr: 0.8746223564954682
============sample only in training=======
5862
7899
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 460
preds.shape: (7899,), labels.shape: (7899,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.931385722216904, f1_test_all: 0.8766437069505322, macro_test: 0.9289467874340018, f1_test: 0.8740629685157421
f1_val_isr: 1.0
f1_test_isr: 0.8740629685157421
============sample only in training=======
5862
7889
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 470
preds.shape: (7889,), labels.shape: (7889,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9325548515473634, f1_test_all: 0.8786346396965866, macro_test: 0.9303779930261847, f1_test: 0.8764215314632297
f1_val_isr: 1.0
f1_test_isr: 0.8764215314632297
============sample only in training=======
5862
7879
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 480
preds.shape: (7879,), labels.shape: (7879,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9335463210565753, f1_test_all: 0.8805031446540881, macro_test: 0.9315942319747763, f1_test: 0.8786737000753579
f1_val_isr: 1.0
f1_test_isr: 0.8786737000753579
============sample only in training=======
5862
7869
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 490
preds.shape: (7869,), labels.shape: (7869,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9323838370819102, f1_test_all: 0.8783269961977187, macro_test: 0.9301930509828618, f1_test: 0.8760456273764258
f1_val_isr: 1.0
f1_test_isr: 0.8760456273764258
============sample only in training=======
5862
7859
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 500
preds.shape: (7859,), labels.shape: (7859,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9322127727372167, f1_test_all: 0.8780795957043589, macro_test: 0.9299972038726364, f1_test: 0.8757575757575757
f1_val_isr: 1.0
f1_test_isr: 0.8757575757575757
============sample only in training=======
5862
7849
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 510
preds.shape: (7849,), labels.shape: (7849,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9326030599641022, f1_test_all: 0.8787301587301588, macro_test: 0.9304827099125774, f1_test: 0.8765243902439025
f1_val_isr: 1.0
f1_test_isr: 0.8765243902439025
============sample only in training=======
5862
7839
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 520
preds.shape: (7839,), labels.shape: (7839,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9324099193594266, f1_test_all: 0.8785982478097621, macro_test: 0.9302611556518834, f1_test: 0.8764044943820225
f1_val_isr: 1.0
f1_test_isr: 0.8764044943820225
============sample only in training=======
5862
7829
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 530
preds.shape: (7829,), labels.shape: (7829,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.932747118205131, f1_test_all: 0.8789808917197452, macro_test: 0.930773437118923, f1_test: 0.877005347593583
f1_val_isr: 1.0
f1_test_isr: 0.877005347593583
============sample only in training=======
5862
7819
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 540
preds.shape: (7819,), labels.shape: (7819,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9331156996961953, f1_test_all: 0.879746835443038, macro_test: 0.9315942319747763, f1_test: 0.8786737000753579
f1_val_isr: 1.0
f1_test_isr: 0.8786737000753579
============sample only in training=======
5862
7809
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 550
preds.shape: (7809,), labels.shape: (7809,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9328920706162818, f1_test_all: 0.8792332268370607, macro_test: 0.9313409480618048, f1_test: 0.8780487804878049
f1_val_isr: 1.0
f1_test_isr: 0.8780487804878049
============sample only in training=======
5862
7799
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 560
preds.shape: (7799,), labels.shape: (7799,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9335767473584946, f1_test_all: 0.880559085133418, macro_test: 0.9323550341378979, f1_test: 0.88
f1_val_isr: 1.0
f1_test_isr: 0.88
============sample only in training=======
5862
7789
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 570
preds.shape: (7789,), labels.shape: (7789,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9335671746718218, f1_test_all: 0.880559085133418, macro_test: 0.9323550341378979, f1_test: 0.88
f1_val_isr: 1.0
f1_test_isr: 0.88
============sample only in training=======
5862
7779
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 580
preds.shape: (7779,), labels.shape: (7779,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9332269127513868, f1_test_all: 0.8800505050505051, macro_test: 0.9319517943027467, f1_test: 0.8794007490636704
f1_val_isr: 1.0
f1_test_isr: 0.8794007490636704
============sample only in training=======
5862
7769
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 590
preds.shape: (7769,), labels.shape: (7769,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.931734793004853, f1_test_all: 0.8773704171934261, macro_test: 0.9297926590121686, f1_test: 0.8755622188905547
f1_val_isr: 1.0
f1_test_isr: 0.8755622188905547
============sample only in training=======
5862
7759
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 600
preds.shape: (7759,), labels.shape: (7759,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9336298157600285, f1_test_all: 0.8806636885768987, macro_test: 0.9305617962340531, f1_test: 0.8767951625094482
f1_val_isr: 1.0
f1_test_isr: 0.8767951625094482
============sample only in training=======
5862
7749
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 610
preds.shape: (7749,), labels.shape: (7749,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9368209230880666, f1_test_all: 0.8866624921728241, macro_test: 0.9344116001446128, f1_test: 0.8839615668883962
f1_val_isr: 1.0
f1_test_isr: 0.8839615668883962
============sample only in training=======
5862
7739
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 620
preds.shape: (7739,), labels.shape: (7739,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9377939234087656, f1_test_all: 0.8883280757097791, macro_test: 0.9355852073633528, f1_test: 0.8859060402684563
f1_val_isr: 1.0
f1_test_isr: 0.8859060402684563
============sample only in training=======
5862
7729
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 630
preds.shape: (7729,), labels.shape: (7729,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.937080364787103, f1_test_all: 0.8869009584664538, macro_test: 0.9343524941817019, f1_test: 0.8835098335854765
f1_val_isr: 1.0
f1_test_isr: 0.8835098335854765
============sample only in training=======
5862
7719
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 640
preds.shape: (7719,), labels.shape: (7719,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9304208312598128, f1_test_all: 0.875462392108508, macro_test: 0.9260819126399678, f1_test: 0.8695652173913043
f1_val_isr: 1.0
f1_test_isr: 0.8695652173913043
============sample only in training=======
5862
7709
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 650
preds.shape: (7709,), labels.shape: (7709,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.936044003451251, f1_test_all: 0.8852459016393442, macro_test: 0.9327690613817782, f1_test: 0.8809523809523809
f1_val_isr: 1.0
f1_test_isr: 0.8809523809523809
============sample only in training=======
5862
7699
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 660
preds.shape: (7699,), labels.shape: (7699,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9359031856743293, f1_test_all: 0.885143570536829, macro_test: 0.9318808897641075, f1_test: 0.8795888399412628
f1_val_isr: 1.0
f1_test_isr: 0.8795888399412628
============sample only in training=======
5862
7689
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 670
preds.shape: (7689,), labels.shape: (7689,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9377088596164811, f1_test_all: 0.8883312421580929, macro_test: 0.934036228240479, f1_test: 0.8833087149187593
f1_val_isr: 1.0
f1_test_isr: 0.8833087149187593
============sample only in training=======
5862
7679
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 680
preds.shape: (7679,), labels.shape: (7679,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9350435318857875, f1_test_all: 0.8836045056320401, macro_test: 0.9308737611376492, f1_test: 0.8777614138438881
f1_val_isr: 1.0
f1_test_isr: 0.8777614138438881
============sample only in training=======
5862
7669
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 690
preds.shape: (7669,), labels.shape: (7669,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9386381175811767, f1_test_all: 0.8900062853551225, macro_test: 0.9351637653496454, f1_test: 0.8852701702442635
f1_val_isr: 1.0
f1_test_isr: 0.8852701702442635
============sample only in training=======
5862
7659
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 700
preds.shape: (7659,), labels.shape: (7659,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9362094422278959, f1_test_all: 0.885678391959799, macro_test: 0.932279270315848, f1_test: 0.8801775147928994
f1_val_isr: 1.0
f1_test_isr: 0.8801775147928994
============sample only in training=======
5862
7649
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 710
preds.shape: (7649,), labels.shape: (7649,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9364114815051662, f1_test_all: 0.886107634543179, macro_test: 0.9325394536403564, f1_test: 0.8807069219440353
f1_val_isr: 1.0
f1_test_isr: 0.8807069219440353
============sample only in training=======
5862
7639
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 1.0
the number of labels is 720
preds.shape: (7639,), labels.shape: (7639,)
preds.shape: (5862,), labels.shape: (5862,)
macro_test_all: 0.9378395491577465, f1_test_all: 0.8886091881686596, macro_test: 0.9342424821599221, f1_test: 0.8836174944403261
f1_val_isr: 1.0
f1_test_isr: 0.8836174944403261
AL Time: 0.337653455324471s
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 5862, self.idx_non_test is 2512
finished loading dataset
current seed is 300
len(idx_non_test) is 2512
len(idx_non_test): 2497
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
-------------initial results------------
micro_val: 0.7000, macro_val: 0.4118
strategy:  uncertainty
============sample global=======
5853
8349
macro_val: 0.4117647058823529
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 10
preds.shape: (8349,), labels.shape: (8349,)
preds.shape: (5853,), labels.shape: (5853,)
macro_test_all: 0.4687579536777806, f1_test_all: 0.0, macro_test: 0.4701249321021184, f1_test: 0.0
f1_val_isr: 0.0
f1_test_isr: 0.0
============sample global=======
5847
8339
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 20
preds.shape: (8339,), labels.shape: (8339,)
preds.shape: (5847,), labels.shape: (5847,)
macro_test_all: 0.7405674845550481, f1_test_all: 0.5279255319148937, macro_test: 0.7411505498272482, f1_test: 0.5271470878578479
f1_val_isr: 0.5
f1_test_isr: 0.5271470878578479
============sample global=======
5838
8329
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 30
preds.shape: (8329,), labels.shape: (8329,)
preds.shape: (5838,), labels.shape: (5838,)
macro_test_all: 0.6305189714886246, f1_test_all: 0.32944228274967574, macro_test: 0.6374747500575315, f1_test: 0.34058656575212864
f1_val_isr: 0.5
f1_test_isr: 0.34058656575212864
============sample global=======
5832
8319
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 40
preds.shape: (8319,), labels.shape: (8319,)
preds.shape: (5832,), labels.shape: (5832,)
macro_test_all: 0.6290967279606208, f1_test_all: 0.3232876712328767, macro_test: 0.6392797270973545, f1_test: 0.34004024144869216
f1_val_isr: 0.5
f1_test_isr: 0.34004024144869216
============sample global=======
5825
8309
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 50
preds.shape: (8309,), labels.shape: (8309,)
preds.shape: (5825,), labels.shape: (5825,)
macro_test_all: 0.6365542673434031, f1_test_all: 0.33054074638233055, macro_test: 0.6430603153041847, f1_test: 0.3404735062006764
f1_val_isr: 0.5
f1_test_isr: 0.3404735062006764
============sample global=======
5817
8299
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 60
preds.shape: (8299,), labels.shape: (8299,)
preds.shape: (5817,), labels.shape: (5817,)
macro_test_all: 0.6851094674418863, f1_test_all: 0.42645074224021595, macro_test: 0.6969551708499961, f1_test: 0.4462151394422311
f1_val_isr: 0.8
f1_test_isr: 0.4462151394422311
============sample global=======
5808
8289
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 70
preds.shape: (8289,), labels.shape: (8289,)
preds.shape: (5808,), labels.shape: (5808,)
macro_test_all: 0.6924719801924059, f1_test_all: 0.4373673036093418, macro_test: 0.6999319271799627, f1_test: 0.4488935721812434
f1_val_isr: 0.8
f1_test_isr: 0.4488935721812434
============sample global=======
5800
8279
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 80
preds.shape: (8279,), labels.shape: (8279,)
preds.shape: (5800,), labels.shape: (5800,)
macro_test_all: 0.710542015744456, f1_test_all: 0.4708362614195363, macro_test: 0.7161462878491271, f1_test: 0.4790794979079498
f1_val_isr: 0.8
f1_test_isr: 0.4790794979079498
============sample global=======
5793
8269
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 90
preds.shape: (8269,), labels.shape: (8269,)
preds.shape: (5793,), labels.shape: (5793,)
macro_test_all: 0.6548149540810799, f1_test_all: 0.3609756097560976, macro_test: 0.6610046204686932, f1_test: 0.37063778580024076
f1_val_isr: 0.5
f1_test_isr: 0.37063778580024076
============sample global=======
5787
8259
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 100
preds.shape: (8259,), labels.shape: (8259,)
preds.shape: (5787,), labels.shape: (5787,)
macro_test_all: 0.686656098241239, f1_test_all: 0.421875, macro_test: 0.6948575715757821, f1_test: 0.435483870967742
f1_val_isr: 0.8
f1_test_isr: 0.435483870967742
============sample global=======
5782
8249
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 110
preds.shape: (8249,), labels.shape: (8249,)
preds.shape: (5782,), labels.shape: (5782,)
macro_test_all: 0.6997813268414421, f1_test_all: 0.4465116279069768, macro_test: 0.7069736639236759, f1_test: 0.4581901489117985
f1_val_isr: 0.8
f1_test_isr: 0.4581901489117985
============sample global=======
5774
8239
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 120
preds.shape: (8239,), labels.shape: (8239,)
preds.shape: (5774,), labels.shape: (5774,)
macro_test_all: 0.6958117980940274, f1_test_all: 0.4382911392405064, macro_test: 0.7050638691869797, f1_test: 0.45380116959064326
f1_val_isr: 0.8
f1_test_isr: 0.45380116959064326
============sample global=======
5769
8229
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 130
preds.shape: (8229,), labels.shape: (8229,)
preds.shape: (5769,), labels.shape: (5769,)
macro_test_all: 0.7052032780937756, f1_test_all: 0.45597484276729566, macro_test: 0.7138536666513686, f1_test: 0.470314318975553
f1_val_isr: 0.8
f1_test_isr: 0.470314318975553
============sample global=======
5762
8219
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 140
preds.shape: (8219,), labels.shape: (8219,)
preds.shape: (5762,), labels.shape: (5762,)
macro_test_all: 0.7012846984461416, f1_test_all: 0.44799999999999995, macro_test: 0.7101108463793593, f1_test: 0.4626334519572954
f1_val_isr: 0.8
f1_test_isr: 0.4626334519572954
============sample global=======
5753
8209
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 150
preds.shape: (8209,), labels.shape: (8209,)
preds.shape: (5753,), labels.shape: (5753,)
macro_test_all: 0.707078217615649, f1_test_all: 0.45922406967537605, macro_test: 0.7148319802292192, f1_test: 0.47169811320754723
f1_val_isr: 0.8
f1_test_isr: 0.47169811320754723
============sample global=======
5745
8199
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 160
preds.shape: (8199,), labels.shape: (8199,)
preds.shape: (5745,), labels.shape: (5745,)
macro_test_all: 0.7094319213357708, f1_test_all: 0.46337579617834396, macro_test: 0.7170619314565552, f1_test: 0.4757396449704142
f1_val_isr: 0.8
f1_test_isr: 0.4757396449704142
============sample global=======
5738
8189
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 170
preds.shape: (8189,), labels.shape: (8189,)
preds.shape: (5738,), labels.shape: (5738,)
macro_test_all: 0.7077217893027348, f1_test_all: 0.4594155844155844, macro_test: 0.714940003702131, f1_test: 0.4710144927536232
f1_val_isr: 0.8
f1_test_isr: 0.4710144927536232
============sample global=======
5732
8179
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 180
preds.shape: (8179,), labels.shape: (8179,)
preds.shape: (5732,), labels.shape: (5732,)
macro_test_all: 0.7176943791706177, f1_test_all: 0.47905138339920944, macro_test: 0.7267144468454707, f1_test: 0.49414519906323173
f1_val_isr: 0.8
f1_test_isr: 0.49414519906323173
============sample global=======
5725
8169
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 190
preds.shape: (8169,), labels.shape: (8169,)
preds.shape: (5725,), labels.shape: (5725,)
macro_test_all: 0.7211533784423809, f1_test_all: 0.4847020933977456, macro_test: 0.7279820376655031, f1_test: 0.4958283671036948
f1_val_isr: 0.8
f1_test_isr: 0.4958283671036948
============sample global=======
5720
8159
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 200
preds.shape: (8159,), labels.shape: (8159,)
preds.shape: (5720,), labels.shape: (5720,)
macro_test_all: 0.7231523741078691, f1_test_all: 0.48827809215844775, macro_test: 0.7299427553190183, f1_test: 0.4994026284348866
f1_val_isr: 0.8
f1_test_isr: 0.4994026284348866
============sample global=======
5715
8149
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 210
preds.shape: (8149,), labels.shape: (8149,)
preds.shape: (5715,), labels.shape: (5715,)
macro_test_all: 0.7223502023590858, f1_test_all: 0.4865744507729861, macro_test: 0.7300245001275021, f1_test: 0.49939975990396157
f1_val_isr: 0.8
f1_test_isr: 0.49939975990396157
============sample global=======
5707
8139
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 220
preds.shape: (8139,), labels.shape: (8139,)
preds.shape: (5707,), labels.shape: (5707,)
macro_test_all: 0.7213503948082874, f1_test_all: 0.48440065681444994, macro_test: 0.7286321311222352, f1_test: 0.4963503649635037
f1_val_isr: 0.8
f1_test_isr: 0.4963503649635037
============sample global=======
5699
8129
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 230
preds.shape: (8129,), labels.shape: (8129,)
preds.shape: (5699,), labels.shape: (5699,)
macro_test_all: 0.7207564195725449, f1_test_all: 0.48304383788254757, macro_test: 0.7290484074766472, f1_test: 0.49694002447980423
f1_val_isr: 0.8
f1_test_isr: 0.49694002447980423
============sample global=======
5695
8119
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 240
preds.shape: (8119,), labels.shape: (8119,)
preds.shape: (5695,), labels.shape: (5695,)
macro_test_all: 0.719722476290271, f1_test_all: 0.48080133555926546, macro_test: 0.7285114205620352, f1_test: 0.4956843403205919
f1_val_isr: 0.8
f1_test_isr: 0.4956843403205919
============sample global=======
5689
8109
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 250
preds.shape: (8109,), labels.shape: (8109,)
preds.shape: (5689,), labels.shape: (5689,)
macro_test_all: 0.7159949018049255, f1_test_all: 0.4732824427480916, macro_test: 0.7247243192377844, f1_test: 0.4881101376720901
f1_val_isr: 0.8
f1_test_isr: 0.4881101376720901
============sample global=======
5681
8099
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 260
preds.shape: (8099,), labels.shape: (8099,)
preds.shape: (5681,), labels.shape: (5681,)
macro_test_all: 0.7132926010132277, f1_test_all: 0.4677558039552881, macro_test: 0.7211690591400954, f1_test: 0.4809160305343512
f1_val_isr: 0.8
f1_test_isr: 0.4809160305343512
============sample global=======
5674
8089
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 270
preds.shape: (8089,), labels.shape: (8089,)
preds.shape: (5674,), labels.shape: (5674,)
macro_test_all: 0.7132976189755794, f1_test_all: 0.4675324675324675, macro_test: 0.721553596119245, f1_test: 0.48143405889884766
f1_val_isr: 0.8
f1_test_isr: 0.48143405889884766
============sample global=======
5667
8079
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 280
preds.shape: (8079,), labels.shape: (8079,)
preds.shape: (5667,), labels.shape: (5667,)
macro_test_all: 0.7137452014405143, f1_test_all: 0.4683434518647008, macro_test: 0.7212238607948208, f1_test: 0.48071979434447304
f1_val_isr: 0.8
f1_test_isr: 0.48071979434447304
============sample global=======
5662
8069
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 290
preds.shape: (8069,), labels.shape: (8069,)
preds.shape: (5662,), labels.shape: (5662,)
macro_test_all: 0.7107072056239016, f1_test_all: 0.4622144112478032, macro_test: 0.719557005998872, f1_test: 0.4773022049286641
f1_val_isr: 0.8
f1_test_isr: 0.4773022049286641
============sample global=======
5655
8059
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 300
preds.shape: (8059,), labels.shape: (8059,)
preds.shape: (5655,), labels.shape: (5655,)
macro_test_all: 0.7104516221751158, f1_test_all: 0.4615384615384615, macro_test: 0.7188947461393282, f1_test: 0.47581699346405226
f1_val_isr: 0.8
f1_test_isr: 0.47581699346405226
============sample global=======
5648
8049
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 310
preds.shape: (8049,), labels.shape: (8049,)
preds.shape: (5648,), labels.shape: (5648,)
macro_test_all: 0.7068212077322933, f1_test_all: 0.4542190305206463, macro_test: 0.7157762784909371, f1_test: 0.46949602122015904
f1_val_isr: 0.8
f1_test_isr: 0.46949602122015904
============sample global=======
5640
8039
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 320
preds.shape: (8039,), labels.shape: (8039,)
preds.shape: (5640,), labels.shape: (5640,)
macro_test_all: 0.7067838415647074, f1_test_all: 0.454054054054054, macro_test: 0.7157682811016144, f1_test: 0.4693333333333333
f1_val_isr: 0.8
f1_test_isr: 0.4693333333333333
============sample global=======
5631
8029
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 330
preds.shape: (8029,), labels.shape: (8029,)
preds.shape: (5631,), labels.shape: (5631,)
macro_test_all: 0.7032641508787439, f1_test_all: 0.44688644688644696, macro_test: 0.7103423961132749, f1_test: 0.4583901773533424
f1_val_isr: 0.8
f1_test_isr: 0.4583901773533424
============sample global=======
5625
8019
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 340
preds.shape: (8019,), labels.shape: (8019,)
preds.shape: (5625,), labels.shape: (5625,)
macro_test_all: 0.6988651058745647, f1_test_all: 0.4380242311276794, macro_test: 0.7058352408624011, f1_test: 0.449375866851595
f1_val_isr: 0.8
f1_test_isr: 0.449375866851595
============sample global=======
5622
8009
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 350
preds.shape: (8009,), labels.shape: (8009,)
preds.shape: (5622,), labels.shape: (5622,)
macro_test_all: 0.6956192691979912, f1_test_all: 0.4314096499526964, macro_test: 0.703524929814226, f1_test: 0.4447552447552447
f1_val_isr: 0.8
f1_test_isr: 0.4447552447552447
============sample global=======
5614
7999
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 360
preds.shape: (7999,), labels.shape: (7999,)
preds.shape: (5614,), labels.shape: (5614,)
macro_test_all: 0.6914823042981888, f1_test_all: 0.42307692307692313, macro_test: 0.6991381536317884, f1_test: 0.43589743589743596
f1_val_isr: 0.8
f1_test_isr: 0.43589743589743596
============sample global=======
5606
7989
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 370
preds.shape: (7989,), labels.shape: (7989,)
preds.shape: (5606,), labels.shape: (5606,)
macro_test_all: 0.6882512640560979, f1_test_all: 0.41642228739002934, macro_test: 0.6937533494452455, f1_test: 0.42503639010189226
f1_val_isr: 0.8
f1_test_isr: 0.42503639010189226
============sample global=======
5601
7979
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 380
preds.shape: (7979,), labels.shape: (7979,)
preds.shape: (5601,), labels.shape: (5601,)
macro_test_all: 0.6861732849317267, f1_test_all: 0.41222879684418146, macro_test: 0.6912133358623638, f1_test: 0.4199706314243759
f1_val_isr: 0.8
f1_test_isr: 0.4199706314243759
============sample global=======
5595
7969
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 390
preds.shape: (7969,), labels.shape: (7969,)
preds.shape: (5595,), labels.shape: (5595,)
macro_test_all: 0.6868626789511793, f1_test_all: 0.41345202769535117, macro_test: 0.6915500643644708, f1_test: 0.4205882352941176
f1_val_isr: 0.8
f1_test_isr: 0.4205882352941176
============sample global=======
5586
7959
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 400
preds.shape: (7959,), labels.shape: (7959,)
preds.shape: (5586,), labels.shape: (5586,)
macro_test_all: 0.6868764482298476, f1_test_all: 0.4131736526946108, macro_test: 0.6924699684835194, f1_test: 0.4219910846953938
f1_val_isr: 0.8
f1_test_isr: 0.4219910846953938
============sample global=======
5582
7949
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 410
preds.shape: (7949,), labels.shape: (7949,)
preds.shape: (5582,), labels.shape: (5582,)
macro_test_all: 0.6823496414568286, f1_test_all: 0.4040609137055838, macro_test: 0.6910976066160361, f1_test: 0.4191616766467065
f1_val_isr: 0.8
f1_test_isr: 0.4191616766467065
============sample global=======
5575
7939
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 420
preds.shape: (7939,), labels.shape: (7939,)
preds.shape: (5575,), labels.shape: (5575,)
macro_test_all: 0.6770387654501995, f1_test_all: 0.39337474120082816, macro_test: 0.6861428015521749, f1_test: 0.40916030534351144
f1_val_isr: 0.8
f1_test_isr: 0.40916030534351144
============sample global=======
5568
7929
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 430
preds.shape: (7929,), labels.shape: (7929,)
preds.shape: (5568,), labels.shape: (5568,)
macro_test_all: 0.6725703766009288, f1_test_all: 0.384453781512605, macro_test: 0.6815556191020875, f1_test: 0.4
f1_val_isr: 0.8
f1_test_isr: 0.4
============sample global=======
5565
7919
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 440
preds.shape: (7919,), labels.shape: (7919,)
preds.shape: (5565,), labels.shape: (5565,)
macro_test_all: 0.6659658034411928, f1_test_all: 0.37124463519313305, macro_test: 0.6787387176936368, f1_test: 0.3943661971830985
f1_val_isr: 0.8
f1_test_isr: 0.3943661971830985
============sample global=======
5557
7909
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 450
preds.shape: (7909,), labels.shape: (7909,)
preds.shape: (5557,), labels.shape: (5557,)
macro_test_all: 0.6611634571800382, f1_test_all: 0.3616557734204793, macro_test: 0.6729361437697071, f1_test: 0.3827751196172249
f1_val_isr: 0.8
f1_test_isr: 0.3827751196172249
============sample global=======
5548
7899
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 460
preds.shape: (7899,), labels.shape: (7899,)
preds.shape: (5548,), labels.shape: (5548,)
macro_test_all: 0.6604427904170743, f1_test_all: 0.3602620087336244, macro_test: 0.6729044191074949, f1_test: 0.3827751196172249
f1_val_isr: 0.8
f1_test_isr: 0.3827751196172249
============sample global=======
5541
7889
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 470
preds.shape: (7889,), labels.shape: (7889,)
preds.shape: (5541,), labels.shape: (5541,)
macro_test_all: 0.6542571063772595, f1_test_all: 0.3478260869565218, macro_test: 0.6672306106776166, f1_test: 0.37133550488599354
f1_val_isr: 0.8
f1_test_isr: 0.37133550488599354
============sample global=======
5536
7879
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 480
preds.shape: (7879,), labels.shape: (7879,)
preds.shape: (5536,), labels.shape: (5536,)
macro_test_all: 0.6468206877564673, f1_test_all: 0.3329532497149373, macro_test: 0.6620264343935602, f1_test: 0.3609271523178808
f1_val_isr: 0.8
f1_test_isr: 0.3609271523178808
============sample global=======
5527
7869
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 490
preds.shape: (7869,), labels.shape: (7869,)
preds.shape: (5527,), labels.shape: (5527,)
macro_test_all: 0.6467942347087572, f1_test_all: 0.3329532497149373, macro_test: 0.6619946766374094, f1_test: 0.3609271523178808
f1_val_isr: 0.8
f1_test_isr: 0.3609271523178808
============sample global=======
5518
7859
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 500
preds.shape: (7859,), labels.shape: (7859,)
preds.shape: (5518,), labels.shape: (5518,)
macro_test_all: 0.6390107253705418, f1_test_all: 0.31738623103850644, macro_test: 0.6521795646422915, f1_test: 0.3412969283276451
f1_val_isr: 0.8
f1_test_isr: 0.3412969283276451
============sample global=======
5511
7849
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 510
preds.shape: (7849,), labels.shape: (7849,)
preds.shape: (5511,), labels.shape: (5511,)
macro_test_all: 0.6316856400101358, f1_test_all: 0.30274135876042907, macro_test: 0.6452906312863173, f1_test: 0.3275261324041812
f1_val_isr: 0.8
f1_test_isr: 0.3275261324041812
============sample global=======
5504
7839
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 520
preds.shape: (7839,), labels.shape: (7839,)
preds.shape: (5504,), labels.shape: (5504,)
macro_test_all: 0.6231721034870641, f1_test_all: 0.28571428571428575, macro_test: 0.6368847079413695, f1_test: 0.3107142857142857
f1_val_isr: 0.8
f1_test_isr: 0.3107142857142857
============sample global=======
5498
7829
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 530
preds.shape: (7829,), labels.shape: (7829,)
preds.shape: (5498,), labels.shape: (5498,)
macro_test_all: 0.6222739496434544, f1_test_all: 0.28396572827417377, macro_test: 0.6356317315900477, f1_test: 0.3082437275985663
f1_val_isr: 0.8
f1_test_isr: 0.3082437275985663
============sample global=======
5489
7819
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 540
preds.shape: (7819,), labels.shape: (7819,)
preds.shape: (5489,), labels.shape: (5489,)
macro_test_all: 0.618717658188391, f1_test_all: 0.276885043263288, macro_test: 0.6305830456463367, f1_test: 0.29818181818181816
f1_val_isr: 0.8
f1_test_isr: 0.29818181818181816
============sample global=======
5482
7809
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 550
preds.shape: (7809,), labels.shape: (7809,)
preds.shape: (5482,), labels.shape: (5482,)
macro_test_all: 0.611417355486136, f1_test_all: 0.2622950819672131, macro_test: 0.6240776271282795, f1_test: 0.28518518518518515
f1_val_isr: 0.8
f1_test_isr: 0.28518518518518515
============sample global=======
5475
7799
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 560
preds.shape: (7799,), labels.shape: (7799,)
preds.shape: (5475,), labels.shape: (5475,)
macro_test_all: 0.6047804396413341, f1_test_all: 0.24903722721437738, macro_test: 0.6173269836671134, f1_test: 0.27169811320754716
f1_val_isr: 0.8
f1_test_isr: 0.27169811320754716
============sample global=======
5469
7789
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 570
preds.shape: (7789,), labels.shape: (7789,)
preds.shape: (5469,), labels.shape: (5469,)
macro_test_all: 0.6047537646309065, f1_test_all: 0.24903722721437738, macro_test: 0.6173056284715676, f1_test: 0.27169811320754716
f1_val_isr: 0.8
f1_test_isr: 0.27169811320754716
============sample global=======
5462
7779
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 580
preds.shape: (7779,), labels.shape: (7779,)
preds.shape: (5462,), labels.shape: (5462,)
macro_test_all: 0.6037632053463188, f1_test_all: 0.2471042471042471, macro_test: 0.6159048643417631, f1_test: 0.2689393939393939
f1_val_isr: 0.8
f1_test_isr: 0.2689393939393939
============sample global=======
5457
7769
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 590
preds.shape: (7769,), labels.shape: (7769,)
preds.shape: (5457,), labels.shape: (5457,)
macro_test_all: 0.6017937773720149, f1_test_all: 0.24320827943078913, macro_test: 0.6131038358962302, f1_test: 0.2633587786259542
f1_val_isr: 0.8
f1_test_isr: 0.2633587786259542
============sample global=======
5451
7759
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 600
preds.shape: (7759,), labels.shape: (7759,)
preds.shape: (5451,), labels.shape: (5451,)
macro_test_all: 0.5978205828525405, f1_test_all: 0.2352941176470588, macro_test: 0.6073862847572089, f1_test: 0.25193798449612403
f1_val_isr: 0.8
f1_test_isr: 0.25193798449612403
============sample global=======
5444
7749
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 610
preds.shape: (7749,), labels.shape: (7749,)
preds.shape: (5444,), labels.shape: (5444,)
macro_test_all: 0.5886045708152929, f1_test_all: 0.21686746987951805, macro_test: 0.5969551411147246, f1_test: 0.23107569721115537
f1_val_isr: 0.8
f1_test_isr: 0.23107569721115537
============sample global=======
5435
7739
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 620
preds.shape: (7739,), labels.shape: (7739,)
preds.shape: (5435,), labels.shape: (5435,)
macro_test_all: 0.5864750109722184, f1_test_all: 0.2126514131897712, macro_test: 0.5953886210221793, f1_test: 0.22799999999999998
f1_val_isr: 0.8
f1_test_isr: 0.22799999999999998
============sample global=======
5428
7729
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 630
preds.shape: (7729,), labels.shape: (7729,)
preds.shape: (5428,), labels.shape: (5428,)
macro_test_all: 0.5864480307539071, f1_test_all: 0.2126514131897712, macro_test: 0.5953634607956739, f1_test: 0.22799999999999998
f1_val_isr: 0.8
f1_test_isr: 0.22799999999999998
============sample global=======
5421
7719
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 640
preds.shape: (7719,), labels.shape: (7719,)
preds.shape: (5421,), labels.shape: (5421,)
macro_test_all: 0.5864209770950557, f1_test_all: 0.2126514131897712, macro_test: 0.595338232450203, f1_test: 0.22799999999999998
f1_val_isr: 0.8
f1_test_isr: 0.22799999999999998
============sample global=======
5414
7709
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 650
preds.shape: (7709,), labels.shape: (7709,)
preds.shape: (5414,), labels.shape: (5414,)
macro_test_all: 0.5788525721355277, f1_test_all: 0.19753086419753085, macro_test: 0.585842819545296, f1_test: 0.209016393442623
f1_val_isr: 0.8
f1_test_isr: 0.209016393442623
============sample global=======
5407
7699
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 660
preds.shape: (7699,), labels.shape: (7699,)
preds.shape: (5407,), labels.shape: (5407,)
macro_test_all: 0.5766171504311226, f1_test_all: 0.19310344827586204, macro_test: 0.584193594144967, f1_test: 0.205761316872428
f1_val_isr: 0.8
f1_test_isr: 0.205761316872428
============sample global=======
5401
7689
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 670
preds.shape: (7689,), labels.shape: (7689,)
preds.shape: (5401,), labels.shape: (5401,)
macro_test_all: 0.5698161224810865, f1_test_all: 0.17952314165497893, macro_test: 0.5792187399082865, f1_test: 0.19583333333333333
f1_val_isr: 0.8
f1_test_isr: 0.19583333333333333
============sample global=======
5392
7679
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 680
preds.shape: (7679,), labels.shape: (7679,)
preds.shape: (5392,), labels.shape: (5392,)
macro_test_all: 0.5686376352179952, f1_test_all: 0.17721518987341772, macro_test: 0.5775073544516863, f1_test: 0.19246861924686193
f1_val_isr: 0.8
f1_test_isr: 0.19246861924686193
============sample global=======
5383
7669
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 690
preds.shape: (7669,), labels.shape: (7669,)
preds.shape: (5383,), labels.shape: (5383,)
macro_test_all: 0.5627553411678161, f1_test_all: 0.1654778887303852, macro_test: 0.5706165583825158, f1_test: 0.17872340425531913
f1_val_isr: 0.8
f1_test_isr: 0.17872340425531913
============sample global=======
5376
7659
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 700
preds.shape: (7659,), labels.shape: (7659,)
preds.shape: (5376,), labels.shape: (5376,)
macro_test_all: 0.5517559791930634, f1_test_all: 0.14348462664714498, macro_test: 0.5598538343869283, f1_test: 0.15720524017467247
f1_val_isr: 0.8
f1_test_isr: 0.15720524017467247
============sample global=======
5370
7649
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 710
preds.shape: (7649,), labels.shape: (7649,)
preds.shape: (5370,), labels.shape: (5370,)
macro_test_all: 0.5479413526425488, f1_test_all: 0.13589364844903987, macro_test: 0.5561265001571787, f1_test: 0.14977973568281938
f1_val_isr: 0.8
f1_test_isr: 0.14977973568281938
============sample global=======
5362
7639
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 720
preds.shape: (7639,), labels.shape: (7639,)
preds.shape: (5362,), labels.shape: (5362,)
macro_test_all: 0.5480500766288804, f1_test_all: 0.13609467455621302, macro_test: 0.5563130982601091, f1_test: 0.15011037527593818
f1_val_isr: 0.8
f1_test_isr: 0.15011037527593818
AL Time: 0.4245298388414085s
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7537, self.idx_non_test is 837
finished loading dataset
current seed is 300
len(idx_non_test) is 837
len(idx_non_test): 822
macro_val: 0.37499999999999994
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
-------------initial results------------
micro_val: 0.6000, macro_val: 0.3750
strategy:  uncertainty
============sample only in training=======
7537
8349
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 10
preds.shape: (8349,), labels.shape: (8349,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.8289601303598464, f1_test_all: 0.6995073891625616, macro_test: 0.8353319710683993, f1_test: 0.711038961038961
f1_val_isr: 0.0
f1_test_isr: 0.711038961038961
============sample only in training=======
7537
8339
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 20
preds.shape: (8339,), labels.shape: (8339,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.8690581837558783, f1_test_all: 0.767416934619507, macro_test: 0.8738750630095791, f1_test: 0.7764156450671336
f1_val_isr: 0.0
f1_test_isr: 0.7764156450671336
============sample only in training=======
7537
8329
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 30
preds.shape: (8329,), labels.shape: (8329,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.8837430035034826, f1_test_all: 0.7977890373099954, macro_test: 0.8860455581690775, f1_test: 0.8022088353413654
f1_val_isr: 0.0
f1_test_isr: 0.8022088353413654
============sample only in training=======
7537
8319
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 40
preds.shape: (8319,), labels.shape: (8319,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.8705868720839147, f1_test_all: 0.770139634801289, macro_test: 0.8741312068573913, f1_test: 0.7769365171811299
f1_val_isr: 0.0
f1_test_isr: 0.7769365171811299
============sample only in training=======
7537
8309
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 50
preds.shape: (8309,), labels.shape: (8309,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.8891887366362838, f1_test_all: 0.8034096963239211, macro_test: 0.8916069276273207, f1_test: 0.8082663605051665
f1_val_isr: 0.0
f1_test_isr: 0.8082663605051665
============sample only in training=======
7537
8299
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 60
preds.shape: (8299,), labels.shape: (8299,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9111206683719426, f1_test_all: 0.8429752066115703, macro_test: 0.91370790972074, f1_test: 0.8481501932633905
f1_val_isr: 0.0
f1_test_isr: 0.8481501932633905
============sample only in training=======
7537
8289
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 70
preds.shape: (8289,), labels.shape: (8289,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9103928243103652, f1_test_all: 0.8414442700156987, macro_test: 0.9127694520232238, f1_test: 0.846325167037862
f1_val_isr: 0.0
f1_test_isr: 0.846325167037862
============sample only in training=======
7537
8279
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 80
preds.shape: (8279,), labels.shape: (8279,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9126365598087729, f1_test_all: 0.8451749734888654, macro_test: 0.914279142754644, f1_test: 0.8487914558740867
f1_val_isr: 0.0
f1_test_isr: 0.8487914558740867
============sample only in training=======
7537
8269
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 90
preds.shape: (8269,), labels.shape: (8269,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9121206716751149, f1_test_all: 0.8442317916002127, macro_test: 0.9133417978342114, f1_test: 0.8472299944040291
f1_val_isr: 0.0
f1_test_isr: 0.8472299944040291
============sample only in training=======
7537
8259
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 100
preds.shape: (8259,), labels.shape: (8259,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9163410423448088, f1_test_all: 0.8514316585629389, macro_test: 0.9175403468270104, f1_test: 0.8543909348441927
f1_val_isr: 0.0
f1_test_isr: 0.8543909348441927
============sample only in training=======
7537
8249
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 110
preds.shape: (8249,), labels.shape: (8249,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9118675998468551, f1_test_all: 0.8431480462300496, macro_test: 0.9133071807553375, f1_test: 0.8466398621481908
f1_val_isr: 0.0
f1_test_isr: 0.8466398621481908
============sample only in training=======
7537
8239
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 120
preds.shape: (8239,), labels.shape: (8239,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9100290442603118, f1_test_all: 0.8405333333333332, macro_test: 0.9110443975691828, f1_test: 0.8433333333333333
f1_val_isr: 0.0
f1_test_isr: 0.8433333333333333
============sample only in training=======
7537
8229
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 130
preds.shape: (8229,), labels.shape: (8229,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9134223241430471, f1_test_all: 0.8463611859838275, macro_test: 0.9143625215856855, f1_test: 0.8489612577203819
f1_val_isr: 0.0
f1_test_isr: 0.8489612577203819
============sample only in training=======
7537
8219
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 140
preds.shape: (8219,), labels.shape: (8219,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9155235855012965, f1_test_all: 0.8502673796791445, macro_test: 0.9160108432891019, f1_test: 0.8520578420467185
f1_val_isr: 0.0
f1_test_isr: 0.8520578420467185
============sample only in training=======
7537
8209
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 150
preds.shape: (8209,), labels.shape: (8209,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9190149475957645, f1_test_all: 0.8568432092291557, macro_test: 0.9185579702508282, f1_test: 0.8569874932028276
f1_val_isr: 0.0
f1_test_isr: 0.8569874932028276
============sample only in training=======
7537
8199
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 160
preds.shape: (8199,), labels.shape: (8199,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9190019648381651, f1_test_all: 0.8568432092291559, macro_test: 0.9182865609661544, f1_test: 0.8565217391304347
f1_val_isr: 0.0
f1_test_isr: 0.8565217391304347
============sample only in training=======
7537
8189
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 170
preds.shape: (8189,), labels.shape: (8189,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9268807347505287, f1_test_all: 0.8703604088219473, macro_test: 0.9262531677772232, f1_test: 0.8700501952035694
f1_val_isr: 0.0
f1_test_isr: 0.8700501952035694
============sample only in training=======
7537
8179
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 180
preds.shape: (8179,), labels.shape: (8179,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9282860188173063, f1_test_all: 0.8727666486193827, macro_test: 0.9280132655274476, f1_test: 0.8731134712129681
f1_val_isr: 0.0
f1_test_isr: 0.8731134712129681
============sample only in training=======
7537
8169
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 190
preds.shape: (8169,), labels.shape: (8169,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9243338428251922, f1_test_all: 0.8660998937300743, macro_test: 0.923906487917908, f1_test: 0.8662280701754387
f1_val_isr: 0.0
f1_test_isr: 0.8662280701754387
============sample only in training=======
7537
8159
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 200
preds.shape: (8159,), labels.shape: (8159,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9283958511516734, f1_test_all: 0.8731942215088282, macro_test: 0.9281422230038161, f1_test: 0.8735505245720596
f1_val_isr: 0.0
f1_test_isr: 0.8735505245720596
============sample only in training=======
7537
8149
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 210
preds.shape: (8149,), labels.shape: (8149,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9299102994624731, f1_test_all: 0.8760593220338982, macro_test: 0.9297192006113089, f1_test: 0.8765027322404371
f1_val_isr: 0.0
f1_test_isr: 0.8765027322404371
============sample only in training=======
7537
8139
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 220
preds.shape: (8139,), labels.shape: (8139,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9316019697768829, f1_test_all: 0.8788853161843516, macro_test: 0.931561273317383, f1_test: 0.8795580110497239
f1_val_isr: 0.0
f1_test_isr: 0.8795580110497239
============sample only in training=======
7537
8129
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 230
preds.shape: (8129,), labels.shape: (8129,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9282291073078932, f1_test_all: 0.872844827586207, macro_test: 0.9280784490984884, f1_test: 0.8733333333333333
f1_val_isr: 0.0
f1_test_isr: 0.8733333333333333
============sample only in training=======
7537
8119
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 240
preds.shape: (8119,), labels.shape: (8119,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9329162101163607, f1_test_all: 0.8812834224598929, macro_test: 0.932944951367028, f1_test: 0.8820286659316428
f1_val_isr: 0.0
f1_test_isr: 0.8820286659316428
============sample only in training=======
7537
8109
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 250
preds.shape: (8109,), labels.shape: (8109,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9295620399666578, f1_test_all: 0.8752025931928687, macro_test: 0.9294862917363186, f1_test: 0.875766016713092
f1_val_isr: 0.0
f1_test_isr: 0.875766016713092
============sample only in training=======
7537
8099
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 260
preds.shape: (8099,), labels.shape: (8099,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9322710336114299, f1_test_all: 0.880255455029271, macro_test: 0.9323586479000224, f1_test: 0.8810958904109589
f1_val_isr: 0.0
f1_test_isr: 0.8810958904109589
============sample only in training=======
7537
8089
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 270
preds.shape: (8089,), labels.shape: (8089,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9284516014514437, f1_test_all: 0.8733905579399142, macro_test: 0.9284218821851529, f1_test: 0.8740331491712707
f1_val_isr: 0.0
f1_test_isr: 0.8740331491712707
============sample only in training=======
7537
8079
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 280
preds.shape: (8079,), labels.shape: (8079,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.928377160294201, f1_test_all: 0.8731019522776573, macro_test: 0.9283650344262597, f1_test: 0.8737430167597765
f1_val_isr: 0.0
f1_test_isr: 0.8737430167597765
============sample only in training=======
7537
8069
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 290
preds.shape: (8069,), labels.shape: (8069,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9278220220332429, f1_test_all: 0.8722371967654986, macro_test: 0.9277976737017067, f1_test: 0.8728484175458079
f1_val_isr: 0.0
f1_test_isr: 0.8728484175458079
============sample only in training=======
7537
8059
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 300
preds.shape: (8059,), labels.shape: (8059,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9296654605993775, f1_test_all: 0.8752061572292468, macro_test: 0.9299392990878077, f1_test: 0.8763410502540938
f1_val_isr: 0.0
f1_test_isr: 0.8763410502540938
============sample only in training=======
7537
8049
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 310
preds.shape: (8049,), labels.shape: (8049,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9257787481383102, f1_test_all: 0.8687734333154794, macro_test: 0.9253598897111273, f1_test: 0.8687534321801208
f1_val_isr: 0.0
f1_test_isr: 0.8687534321801208
============sample only in training=======
7537
8039
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 320
preds.shape: (8039,), labels.shape: (8039,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9308853620372439, f1_test_all: 0.8778135048231511, macro_test: 0.9311575312504012, f1_test: 0.8790849673202615
f1_val_isr: 0.0
f1_test_isr: 0.8790849673202615
============sample only in training=======
7537
8029
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 330
preds.shape: (8029,), labels.shape: (8029,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9264183196685483, f1_test_all: 0.8698001080497029, macro_test: 0.9266090965778868, f1_test: 0.870950027457441
f1_val_isr: 0.0
f1_test_isr: 0.870950027457441
============sample only in training=======
7537
8019
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 340
preds.shape: (8019,), labels.shape: (8019,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9283794042781226, f1_test_all: 0.8730853391684902, macro_test: 0.9287093398958699, f1_test: 0.8744444444444445
f1_val_isr: 0.0
f1_test_isr: 0.8744444444444445
============sample only in training=======
7537
8009
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 350
preds.shape: (8009,), labels.shape: (8009,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9283678986187764, f1_test_all: 0.8730853391684902, macro_test: 0.928845970688932, f1_test: 0.8747228381374723
f1_val_isr: 0.0
f1_test_isr: 0.8747228381374723
============sample only in training=======
7537
7999
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 360
preds.shape: (7999,), labels.shape: (7999,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.929524425158103, f1_test_all: 0.8751369112814896, macro_test: 0.9301722126125658, f1_test: 0.877076411960133
f1_val_isr: 0.0
f1_test_isr: 0.877076411960133
============sample only in training=======
7537
7989
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 370
preds.shape: (7989,), labels.shape: (7989,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9294517258623476, f1_test_all: 0.8749311294765839, macro_test: 0.9301187016759032, f1_test: 0.8768802228412257
f1_val_isr: 0.0
f1_test_isr: 0.8768802228412257
============sample only in training=======
7537
7979
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 380
preds.shape: (7979,), labels.shape: (7979,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9279212646201594, f1_test_all: 0.8723287671232878, macro_test: 0.92856534162375, f1_test: 0.8742382271468143
f1_val_isr: 0.0
f1_test_isr: 0.8742382271468143
============sample only in training=======
7537
7969
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 390
preds.shape: (7969,), labels.shape: (7969,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9277036321369918, f1_test_all: 0.8719912472647703, macro_test: 0.9284218821851529, f1_test: 0.8740331491712707
f1_val_isr: 0.0
f1_test_isr: 0.8740331491712707
============sample only in training=======
7537
7959
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 400
preds.shape: (7959,), labels.shape: (7959,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9256441595582376, f1_test_all: 0.8684782608695653, macro_test: 0.9263316880611687, f1_test: 0.8704720087815588
f1_val_isr: 0.0
f1_test_isr: 0.8704720087815588
============sample only in training=======
7537
7949
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 410
preds.shape: (7949,), labels.shape: (7949,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.926519138775875, f1_test_all: 0.8700380641653072, macro_test: 0.9272337000112665, f1_test: 0.8720483250961011
f1_val_isr: 0.0
f1_test_isr: 0.8720483250961011
============sample only in training=======
7537
7939
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 420
preds.shape: (7939,), labels.shape: (7939,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9289090767679333, f1_test_all: 0.8741066520065971, macro_test: 0.9296894377095223, f1_test: 0.8761799000555246
f1_val_isr: 0.0
f1_test_isr: 0.8761799000555246
============sample only in training=======
7537
7929
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 430
preds.shape: (7929,), labels.shape: (7929,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9295858356926545, f1_test_all: 0.8753432180120813, macro_test: 0.9303868296432243, f1_test: 0.877426511369939
f1_val_isr: 0.0
f1_test_isr: 0.877426511369939
============sample only in training=======
7537
7919
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 440
preds.shape: (7919,), labels.shape: (7919,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9310399870189134, f1_test_all: 0.8778330569375346, macro_test: 0.9318846148397806, f1_test: 0.8799553322166387
f1_val_isr: 0.0
f1_test_isr: 0.8799553322166387
============sample only in training=======
7537
7909
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 450
preds.shape: (7909,), labels.shape: (7909,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9257926935747365, f1_test_all: 0.8689057421451788, macro_test: 0.9262637251727082, f1_test: 0.8704209950792783
f1_val_isr: 0.0
f1_test_isr: 0.8704209950792783
============sample only in training=======
7537
7899
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 460
preds.shape: (7899,), labels.shape: (7899,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9290600662804214, f1_test_all: 0.8745910577971646, macro_test: 0.9295986722666407, f1_test: 0.876169510181618
f1_val_isr: 0.0
f1_test_isr: 0.876169510181618
============sample only in training=======
7537
7889
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 470
preds.shape: (7889,), labels.shape: (7889,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.930537658441996, f1_test_all: 0.8768802228412257, macro_test: 0.9311348491185893, f1_test: 0.8785151856017996
f1_val_isr: 0.0
f1_test_isr: 0.8785151856017996
============sample only in training=======
7537
7879
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 480
preds.shape: (7879,), labels.shape: (7879,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9271832222505159, f1_test_all: 0.8712328767123287, macro_test: 0.9277250279842408, f1_test: 0.8727876106194691
f1_val_isr: 0.0
f1_test_isr: 0.8727876106194691
============sample only in training=======
7537
7869
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 490
preds.shape: (7869,), labels.shape: (7869,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9310768921887976, f1_test_all: 0.8778583379810374, macro_test: 0.9317059294969506, f1_test: 0.8795045045045045
f1_val_isr: 0.0
f1_test_isr: 0.8795045045045045
============sample only in training=======
7537
7859
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 500
preds.shape: (7859,), labels.shape: (7859,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9269532573061551, f1_test_all: 0.8708971553610503, macro_test: 0.9275146441654216, f1_test: 0.8724461623412479
f1_val_isr: 0.0
f1_test_isr: 0.8724461623412479
============sample only in training=======
7537
7849
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 510
preds.shape: (7849,), labels.shape: (7849,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9274915035631868, f1_test_all: 0.8719346049046321, macro_test: 0.9280683575297783, f1_test: 0.8734873487348735
f1_val_isr: 0.0
f1_test_isr: 0.8734873487348735
============sample only in training=======
7537
7839
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 520
preds.shape: (7839,), labels.shape: (7839,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9265225515586477, f1_test_all: 0.8703201302224634, macro_test: 0.9270939985237392, f1_test: 0.8718510405257393
f1_val_isr: 0.0
f1_test_isr: 0.8718510405257393
============sample only in training=======
7537
7829
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 530
preds.shape: (7829,), labels.shape: (7829,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9244869791618051, f1_test_all: 0.8669527896995709, macro_test: 0.9251016592016734, f1_test: 0.8685776095186587
f1_val_isr: 0.0
f1_test_isr: 0.8685776095186587
============sample only in training=======
7537
7819
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 540
preds.shape: (7819,), labels.shape: (7819,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9276607949078528, f1_test_all: 0.8722707423580784, macro_test: 0.9283470931069365, f1_test: 0.8739680792515135
f1_val_isr: 0.0
f1_test_isr: 0.8739680792515135
============sample only in training=======
7537
7809
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 550
preds.shape: (7809,), labels.shape: (7809,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9298756053044539, f1_test_all: 0.875968992248062, macro_test: 0.9306173518600557, f1_test: 0.8777219430485763
f1_val_isr: 0.0
f1_test_isr: 0.8777219430485763
============sample only in training=======
7537
7799
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 560
preds.shape: (7799,), labels.shape: (7799,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9255215135195549, f1_test_all: 0.8687196110210698, macro_test: 0.926471668445638, f1_test: 0.8709327548806941
f1_val_isr: 0.0
f1_test_isr: 0.8709327548806941
============sample only in training=======
7537
7789
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 570
preds.shape: (7789,), labels.shape: (7789,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9273486469008059, f1_test_all: 0.8717105263157896, macro_test: 0.9283470931069365, f1_test: 0.8739680792515135
f1_val_isr: 0.0
f1_test_isr: 0.8739680792515135
============sample only in training=======
7537
7779
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 580
preds.shape: (7779,), labels.shape: (7779,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9246004578516736, f1_test_all: 0.8670645686380901, macro_test: 0.9255757094598931, f1_test: 0.869281045751634
f1_val_isr: 0.0
f1_test_isr: 0.869281045751634
============sample only in training=======
7537
7769
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 590
preds.shape: (7769,), labels.shape: (7769,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9262916154421414, f1_test_all: 0.8699453551912568, macro_test: 0.9273025606736518, f1_test: 0.8721886999451454
f1_val_isr: 0.0
f1_test_isr: 0.8721886999451454
============sample only in training=======
7537
7759
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 600
preds.shape: (7759,), labels.shape: (7759,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9262789312484629, f1_test_all: 0.8699453551912568, macro_test: 0.9273025606736518, f1_test: 0.8721886999451454
f1_val_isr: 0.0
f1_test_isr: 0.8721886999451454
============sample only in training=======
7537
7749
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 610
preds.shape: (7749,), labels.shape: (7749,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9264748938661982, f1_test_all: 0.8703703703703703, macro_test: 0.9272313847037446, f1_test: 0.8721311475409836
f1_val_isr: 0.0
f1_test_isr: 0.8721311475409836
============sample only in training=======
7537
7739
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 620
preds.shape: (7739,), labels.shape: (7739,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9296573077458701, f1_test_all: 0.8756936736958935, macro_test: 0.9299711214906332, f1_test: 0.8766666666666666
f1_val_isr: 0.0
f1_test_isr: 0.8766666666666666
============sample only in training=======
7537
7729
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 630
preds.shape: (7729,), labels.shape: (7729,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9308060644774154, f1_test_all: 0.8778877887788779, macro_test: 0.9311304354182629, f1_test: 0.8788546255506607
f1_val_isr: 0.0
f1_test_isr: 0.8788546255506607
============sample only in training=======
7537
7719
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 640
preds.shape: (7719,), labels.shape: (7719,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9296912714999216, f1_test_all: 0.875896304467733, macro_test: 0.930024959519, f1_test: 0.8768636112644947
f1_val_isr: 0.0
f1_test_isr: 0.8768636112644947
============sample only in training=======
7537
7709
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 650
preds.shape: (7709,), labels.shape: (7709,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9299118446090457, f1_test_all: 0.8761160714285715, macro_test: 0.9302668476715803, f1_test: 0.877094972067039
f1_val_isr: 0.0
f1_test_isr: 0.877094972067039
============sample only in training=======
7537
7699
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 660
preds.shape: (7699,), labels.shape: (7699,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9289181263117232, f1_test_all: 0.8743718592964824, macro_test: 0.9292817542406202, f1_test: 0.8753493571827836
f1_val_isr: 0.0
f1_test_isr: 0.8753493571827836
============sample only in training=======
7537
7689
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 670
preds.shape: (7689,), labels.shape: (7689,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.930923938675328, f1_test_all: 0.877632327831531, macro_test: 0.9313201435132511, f1_test: 0.8786324786324786
f1_val_isr: 0.0
f1_test_isr: 0.8786324786324786
============sample only in training=======
7537
7679
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 680
preds.shape: (7679,), labels.shape: (7679,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.931825141627429, f1_test_all: 0.8793201133144477, macro_test: 0.9319453601625975, f1_test: 0.8798185941043083
f1_val_isr: 0.0
f1_test_isr: 0.8798185941043083
============sample only in training=======
7537
7669
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 690
preds.shape: (7669,), labels.shape: (7669,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.928551195854894, f1_test_all: 0.8731082654249127, macro_test: 0.9286853051907413, f1_test: 0.87361677344205
f1_val_isr: 0.0
f1_test_isr: 0.87361677344205
============sample only in training=======
7537
7659
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 700
preds.shape: (7659,), labels.shape: (7659,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9271839427668258, f1_test_all: 0.8714524207011687, macro_test: 0.9270269560009572, f1_test: 0.8714524207011687
f1_val_isr: 0.0
f1_test_isr: 0.8714524207011687
============sample only in training=======
7537
7649
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 710
preds.shape: (7649,), labels.shape: (7649,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9288682465364113, f1_test_all: 0.874224478285392, macro_test: 0.9287294107839259, f1_test: 0.874224478285392
f1_val_isr: 0.0
f1_test_isr: 0.874224478285392
============sample only in training=======
7537
7639
macro_val: 1.0
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 720
preds.shape: (7639,), labels.shape: (7639,)
preds.shape: (7537,), labels.shape: (7537,)
macro_test_all: 0.9282202348651956, f1_test_all: 0.8730158730158729, macro_test: 0.9280932107378388, f1_test: 0.8730158730158729
f1_val_isr: 0.0
f1_test_isr: 0.8730158730158729
AL Time: 0.3431964507326484s
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7537, self.idx_non_test is 837
finished loading dataset
current seed is 300
len(idx_non_test) is 837
len(idx_non_test): 822
macro_val: 0.37499999999999994
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
-------------initial results------------
micro_val: 0.6000, macro_val: 0.3750
strategy:  uncertainty
============sample global=======
7529
8349
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 10
preds.shape: (8349,), labels.shape: (8349,)
preds.shape: (7529,), labels.shape: (7529,)
macro_test_all: 0.8221947172991335, f1_test_all: 0.688963210702341, macro_test: 0.8268450150320125, f1_test: 0.6974789915966386
f1_val_isr: 0.0
f1_test_isr: 0.6974789915966386
============sample global=======
7519
8339
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 20
preds.shape: (8339,), labels.shape: (8339,)
preds.shape: (7519,), labels.shape: (7519,)
macro_test_all: 0.7349925420606847, f1_test_all: 0.5288720992984349, macro_test: 0.7369246062905903, f1_test: 0.5326991676575507
f1_val_isr: 0.0
f1_test_isr: 0.5326991676575507
============sample global=======
7509
8329
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 30
preds.shape: (8329,), labels.shape: (8329,)
preds.shape: (7509,), labels.shape: (7509,)
macro_test_all: 0.8303124206895043, f1_test_all: 0.7013506753376688, macro_test: 0.8342396854474332, f1_test: 0.7087218869994515
f1_val_isr: 0.0
f1_test_isr: 0.7087218869994515
============sample global=======
7501
8319
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 40
preds.shape: (8319,), labels.shape: (8319,)
preds.shape: (7501,), labels.shape: (7501,)
macro_test_all: 0.750326519792247, f1_test_all: 0.5509838998211092, macro_test: 0.7526062238445927, f1_test: 0.5557729941291586
f1_val_isr: 0.0
f1_test_isr: 0.5557729941291586
============sample global=======
7491
8309
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 50
preds.shape: (8309,), labels.shape: (8309,)
preds.shape: (7491,), labels.shape: (7491,)
macro_test_all: 0.8011862807105894, f1_test_all: 0.6441260744985673, macro_test: 0.8041814655157823, f1_test: 0.6498740554156172
f1_val_isr: 0.0
f1_test_isr: 0.6498740554156172
============sample global=======
7481
8299
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 60
preds.shape: (8299,), labels.shape: (8299,)
preds.shape: (7481,), labels.shape: (7481,)
macro_test_all: 0.7935466748850799, f1_test_all: 0.6296079578700995, macro_test: 0.7996204163940323, f1_test: 0.641025641025641
f1_val_isr: 0.0
f1_test_isr: 0.641025641025641
============sample global=======
7471
8289
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 70
preds.shape: (8289,), labels.shape: (8289,)
preds.shape: (7471,), labels.shape: (7471,)
macro_test_all: 0.8533017833933717, f1_test_all: 0.7373271889400921, macro_test: 0.8572814446765664, f1_test: 0.7449748743718592
f1_val_isr: 0.0
f1_test_isr: 0.7449748743718592
============sample global=======
7464
8279
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 80
preds.shape: (8279,), labels.shape: (8279,)
preds.shape: (7464,), labels.shape: (7464,)
macro_test_all: 0.8815463454885288, f1_test_all: 0.7912646013204672, macro_test: 0.88650639879816, f1_test: 0.8004434589800443
f1_val_isr: 0.0
f1_test_isr: 0.8004434589800443
============sample global=======
7454
8269
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 90
preds.shape: (8269,), labels.shape: (8269,)
preds.shape: (7454,), labels.shape: (7454,)
macro_test_all: 0.8652394903041991, f1_test_all: 0.76056338028169, macro_test: 0.868126287712875, f1_test: 0.7661338069863824
f1_val_isr: 0.0
f1_test_isr: 0.7661338069863824
============sample global=======
7446
8259
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 100
preds.shape: (8259,), labels.shape: (8259,)
preds.shape: (7446,), labels.shape: (7446,)
macro_test_all: 0.8919579532921695, f1_test_all: 0.8088235294117647, macro_test: 0.8931709746959668, f1_test: 0.811277330264672
f1_val_isr: 0.0
f1_test_isr: 0.811277330264672
============sample global=======
7436
8249
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 110
preds.shape: (8249,), labels.shape: (8249,)
preds.shape: (7436,), labels.shape: (7436,)
macro_test_all: 0.8965689915975539, f1_test_all: 0.8171368861024033, macro_test: 0.8981191898279415, f1_test: 0.8201603665521192
f1_val_isr: 0.0
f1_test_isr: 0.8201603665521192
============sample global=======
7428
8239
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 120
preds.shape: (8239,), labels.shape: (8239,)
preds.shape: (7428,), labels.shape: (7428,)
macro_test_all: 0.9156182461948774, f1_test_all: 0.8515151515151516, macro_test: 0.9156151826069028, f1_test: 0.8517699115044247
f1_val_isr: 0.0
f1_test_isr: 0.8517699115044247
============sample global=======
7421
8229
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 130
preds.shape: (8229,), labels.shape: (8229,)
preds.shape: (7421,), labels.shape: (7421,)
macro_test_all: 0.9172844210907594, f1_test_all: 0.8542199488491048, macro_test: 0.917532928772336, f1_test: 0.8549019607843137
f1_val_isr: 0.0
f1_test_isr: 0.8549019607843137
============sample global=======
7412
8219
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 140
preds.shape: (8219,), labels.shape: (8219,)
preds.shape: (7412,), labels.shape: (7412,)
macro_test_all: 0.9118776790333988, f1_test_all: 0.8443519000520563, macro_test: 0.9145315100275941, f1_test: 0.8493462194428653
f1_val_isr: 0.0
f1_test_isr: 0.8493462194428653
============sample global=======
7404
8209
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 150
preds.shape: (8209,), labels.shape: (8209,)
preds.shape: (7404,), labels.shape: (7404,)
macro_test_all: 0.9138653675382215, f1_test_all: 0.8479501816294759, macro_test: 0.9165828178908588, f1_test: 0.8531073446327684
f1_val_isr: 0.0
f1_test_isr: 0.8531073446327684
============sample global=======
7394
8199
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 160
preds.shape: (8199,), labels.shape: (8199,)
preds.shape: (7394,), labels.shape: (7394,)
macro_test_all: 0.9180745667400099, f1_test_all: 0.8551941238195173, macro_test: 0.9209284509017598, f1_test: 0.8605714285714288
f1_val_isr: 0.0
f1_test_isr: 0.8605714285714288
============sample global=======
7385
8189
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 170
preds.shape: (8189,), labels.shape: (8189,)
preds.shape: (7385,), labels.shape: (7385,)
macro_test_all: 0.912301945331712, f1_test_all: 0.8445873526259378, macro_test: 0.9155169652458417, f1_test: 0.8506417736289381
f1_val_isr: 0.0
f1_test_isr: 0.8506417736289381
============sample global=======
7375
8179
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 180
preds.shape: (8179,), labels.shape: (8179,)
preds.shape: (7375,), labels.shape: (7375,)
macro_test_all: 0.9213437375476401, f1_test_all: 0.8607863974495218, macro_test: 0.9239623685273355, f1_test: 0.8657407407407407
f1_val_isr: 0.0
f1_test_isr: 0.8657407407407407
============sample global=======
7367
8169
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 190
preds.shape: (8169,), labels.shape: (8169,)
preds.shape: (7367,), labels.shape: (7367,)
macro_test_all: 0.9238575549609909, f1_test_all: 0.865210442194992, macro_test: 0.9264260402938307, f1_test: 0.8700696055684455
f1_val_isr: 0.0
f1_test_isr: 0.8700696055684455
============sample global=======
7357
8159
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 200
preds.shape: (8159,), labels.shape: (8159,)
preds.shape: (7357,), labels.shape: (7357,)
macro_test_all: 0.92638381547076, f1_test_all: 0.8696581196581197, macro_test: 0.928460306394796, f1_test: 0.8736167734420501
f1_val_isr: 0.0
f1_test_isr: 0.8736167734420501
============sample global=======
7349
8149
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 210
preds.shape: (8149,), labels.shape: (8149,)
preds.shape: (7349,), labels.shape: (7349,)
macro_test_all: 0.9291920508908392, f1_test_all: 0.8745980707395499, macro_test: 0.9313133622496335, f1_test: 0.8786464410735122
f1_val_isr: 0.0
f1_test_isr: 0.8786464410735122
============sample global=======
7339
8139
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 220
preds.shape: (8139,), labels.shape: (8139,)
preds.shape: (7339,), labels.shape: (7339,)
macro_test_all: 0.9296016653985738, f1_test_all: 0.8751357220412596, macro_test: 0.9328982211971149, f1_test: 0.8812758417011224
f1_val_isr: 0.0
f1_test_isr: 0.8812758417011224
============sample global=======
7331
8129
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 230
preds.shape: (8129,), labels.shape: (8129,)
preds.shape: (7331,), labels.shape: (7331,)
macro_test_all: 0.9309577225827107, f1_test_all: 0.8775176918889495, macro_test: 0.9341565802911749, f1_test: 0.8835008870490834
f1_val_isr: 0.0
f1_test_isr: 0.8835008870490834
============sample global=======
7321
8119
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 240
preds.shape: (8119,), labels.shape: (8119,)
preds.shape: (7321,), labels.shape: (7321,)
macro_test_all: 0.9308367852158388, f1_test_all: 0.8771349862258953, macro_test: 0.9341349373903698, f1_test: 0.8833034111310593
f1_val_isr: 0.0
f1_test_isr: 0.8833034111310593
============sample global=======
7311
8109
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 250
preds.shape: (8109,), labels.shape: (8109,)
preds.shape: (7311,), labels.shape: (7311,)
macro_test_all: 0.9327519870069563, f1_test_all: 0.8805723720418271, macro_test: 0.9354072984612247, f1_test: 0.8855602156980228
f1_val_isr: 0.0
f1_test_isr: 0.8855602156980228
============sample global=======
7303
8099
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 260
preds.shape: (8099,), labels.shape: (8099,)
preds.shape: (7303,), labels.shape: (7303,)
macro_test_all: 0.93387750562488, f1_test_all: 0.8824833702882483, macro_test: 0.9367922175338151, f1_test: 0.8879518072289155
f1_val_isr: 0.0
f1_test_isr: 0.8879518072289155
============sample global=======
7294
8089
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 270
preds.shape: (8089,), labels.shape: (8089,)
preds.shape: (7294,), labels.shape: (7294,)
macro_test_all: 0.9343892062119328, f1_test_all: 0.8833054159687326, macro_test: 0.9373738934823859, f1_test: 0.8888888888888888
f1_val_isr: 0.0
f1_test_isr: 0.8888888888888888
============sample global=======
7285
8079
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 280
preds.shape: (8079,), labels.shape: (8079,)
preds.shape: (7285,), labels.shape: (7285,)
macro_test_all: 0.9362338060176205, f1_test_all: 0.8865168539325843, macro_test: 0.9387179334012097, f1_test: 0.89119804400978
f1_val_isr: 0.0
f1_test_isr: 0.89119804400978
============sample global=======
7276
8069
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 290
preds.shape: (8069,), labels.shape: (8069,)
preds.shape: (7276,), labels.shape: (7276,)
macro_test_all: 0.9366683651380737, f1_test_all: 0.887260428410372, macro_test: 0.9388894954771843, f1_test: 0.891477621091355
f1_val_isr: 0.0
f1_test_isr: 0.891477621091355
============sample global=======
7266
8059
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 300
preds.shape: (8059,), labels.shape: (8059,)
preds.shape: (7266,), labels.shape: (7266,)
macro_test_all: 0.9379662018521657, f1_test_all: 0.8895184135977336, macro_test: 0.9403175355133375, f1_test: 0.8939580764488285
f1_val_isr: 0.0
f1_test_isr: 0.8939580764488285
============sample global=======
7256
8049
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 310
preds.shape: (8049,), labels.shape: (8049,)
preds.shape: (7256,), labels.shape: (7256,)
macro_test_all: 0.9385137186825023, f1_test_all: 0.8904109589041096, macro_test: 0.9409340440337756, f1_test: 0.8949658172778123
f1_val_isr: 0.0
f1_test_isr: 0.8949658172778123
============sample global=======
7249
8039
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 320
preds.shape: (8039,), labels.shape: (8039,)
preds.shape: (7249,), labels.shape: (7249,)
macro_test_all: 0.9387146449934438, f1_test_all: 0.8906789413118528, macro_test: 0.9413064923853245, f1_test: 0.8955597248280175
f1_val_isr: 0.0
f1_test_isr: 0.8955597248280175
============sample global=======
7241
8029
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 330
preds.shape: (8029,), labels.shape: (8029,)
preds.shape: (7241,), labels.shape: (7241,)
macro_test_all: 0.9389178035317195, f1_test_all: 0.8909512761020882, macro_test: 0.9416817327417315, f1_test: 0.8961611076148521
f1_val_isr: 0.0
f1_test_isr: 0.8961611076148521
============sample global=======
7231
8019
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 340
preds.shape: (8019,), labels.shape: (8019,)
preds.shape: (7231,), labels.shape: (7231,)
macro_test_all: 0.9394817067511828, f1_test_all: 0.8918760958503799, macro_test: 0.9423181692483322, f1_test: 0.897208121827411
f1_val_isr: 0.0
f1_test_isr: 0.897208121827411
============sample global=======
7222
8009
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 350
preds.shape: (8009,), labels.shape: (8009,)
preds.shape: (7222,), labels.shape: (7222,)
macro_test_all: 0.9395195698632413, f1_test_all: 0.8918918918918918, macro_test: 0.9423764954151892, f1_test: 0.8972559029993619
f1_val_isr: 0.0
f1_test_isr: 0.8972559029993619
============sample global=======
7215
7999
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 360
preds.shape: (7999,), labels.shape: (7999,)
preds.shape: (7215,), labels.shape: (7215,)
macro_test_all: 0.9399815931536162, f1_test_all: 0.892688679245283, macro_test: 0.9430217210178444, f1_test: 0.8984025559105431
f1_val_isr: 0.0
f1_test_isr: 0.8984025559105431
============sample global=======
7206
7989
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 370
preds.shape: (7989,), labels.shape: (7989,)
preds.shape: (7206,), labels.shape: (7206,)
macro_test_all: 0.9412859026466236, f1_test_all: 0.8949554896142433, macro_test: 0.9444619607942053, f1_test: 0.9009009009009009
f1_val_isr: 0.0
f1_test_isr: 0.9009009009009009
============sample global=======
7200
7979
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 380
preds.shape: (7979,), labels.shape: (7979,)
preds.shape: (7200,), labels.shape: (7200,)
macro_test_all: 0.9423627984473995, f1_test_all: 0.8968395945140131, macro_test: 0.9453838475140331, f1_test: 0.9025177533892833
f1_val_isr: 0.0
f1_test_isr: 0.9025177533892833
============sample global=======
7192
7969
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 390
preds.shape: (7969,), labels.shape: (7969,)
preds.shape: (7192,), labels.shape: (7192,)
macro_test_all: 0.9424146177101766, f1_test_all: 0.8968824940047962, macro_test: 0.9455216558992654, f1_test: 0.9027237354085603
f1_val_isr: 0.0
f1_test_isr: 0.9027237354085603
============sample global=======
7183
7959
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 400
preds.shape: (7959,), labels.shape: (7959,)
preds.shape: (7183,), labels.shape: (7183,)
macro_test_all: 0.9436322958671197, f1_test_all: 0.8989715668481548, macro_test: 0.9465388869268183, f1_test: 0.9044502617801048
f1_val_isr: 0.0
f1_test_isr: 0.9044502617801048
============sample global=======
7174
7949
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 410
preds.shape: (7949,), labels.shape: (7949,)
preds.shape: (7174,), labels.shape: (7174,)
macro_test_all: 0.9458609087062095, f1_test_all: 0.9028711056811239, macro_test: 0.9486498907919443, f1_test: 0.9081295439524123
f1_val_isr: 0.0
f1_test_isr: 0.9081295439524123
============sample global=======
7164
7939
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 420
preds.shape: (7939,), labels.shape: (7939,)
preds.shape: (7164,), labels.shape: (7164,)
macro_test_all: 0.9455148653710767, f1_test_all: 0.9021065675340769, macro_test: 0.9483166062162351, f1_test: 0.9073825503355705
f1_val_isr: 0.0
f1_test_isr: 0.9073825503355705
============sample global=======
7154
7929
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 430
preds.shape: (7929,), labels.shape: (7929,)
preds.shape: (7154,), labels.shape: (7154,)
macro_test_all: 0.9486738114724416, f1_test_all: 0.9077306733167083, macro_test: 0.951767670383199, f1_test: 0.9135135135135136
f1_val_isr: 0.0
f1_test_isr: 0.9135135135135136
============sample global=======
7144
7919
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 440
preds.shape: (7919,), labels.shape: (7919,)
preds.shape: (7144,), labels.shape: (7144,)
macro_test_all: 0.9496636403123113, f1_test_all: 0.909433962264151, macro_test: 0.9528726100241677, f1_test: 0.9154160982264666
f1_val_isr: 0.0
f1_test_isr: 0.9154160982264666
============sample global=======
7138
7909
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 450
preds.shape: (7909,), labels.shape: (7909,)
preds.shape: (7138,), labels.shape: (7138,)
macro_test_all: 0.9505672271375382, f1_test_all: 0.9110410094637224, macro_test: 0.9535721719221563, f1_test: 0.9166666666666666
f1_val_isr: 0.0
f1_test_isr: 0.9166666666666666
============sample global=======
7128
7899
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 460
preds.shape: (7899,), labels.shape: (7899,)
preds.shape: (7128,), labels.shape: (7128,)
macro_test_all: 0.9504379580363418, f1_test_all: 0.9107142857142857, macro_test: 0.9534661158201059, f1_test: 0.9163787145818935
f1_val_isr: 0.0
f1_test_isr: 0.9163787145818935
============sample global=======
7119
7889
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 470
preds.shape: (7889,), labels.shape: (7889,)
preds.shape: (7119,), labels.shape: (7119,)
macro_test_all: 0.9507474994679719, f1_test_all: 0.9111969111969113, macro_test: 0.9538892370881062, f1_test: 0.9170731707317072
f1_val_isr: 0.0
f1_test_isr: 0.9170731707317072
============sample global=======
7110
7879
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 480
preds.shape: (7879,), labels.shape: (7879,)
preds.shape: (7110,), labels.shape: (7110,)
macro_test_all: 0.9506730805832699, f1_test_all: 0.9109811565951917, macro_test: 0.9538990467260509, f1_test: 0.9170182841068917
f1_val_isr: 0.0
f1_test_isr: 0.9170182841068917
============sample global=======
7100
7869
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 490
preds.shape: (7869,), labels.shape: (7869,)
preds.shape: (7100,), labels.shape: (7100,)
macro_test_all: 0.9514368430166795, f1_test_all: 0.9123036649214659, macro_test: 0.954752708450781, f1_test: 0.9184975194897237
f1_val_isr: 0.0
f1_test_isr: 0.9184975194897237
============sample global=======
7091
7859
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 500
preds.shape: (7859,), labels.shape: (7859,)
preds.shape: (7091,), labels.shape: (7091,)
macro_test_all: 0.9536590803975007, f1_test_all: 0.9163398692810457, macro_test: 0.9563754042724559, f1_test: 0.921443736730361
f1_val_isr: 0.0
f1_test_isr: 0.921443736730361
============sample global=======
7082
7849
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 510
preds.shape: (7849,), labels.shape: (7849,)
preds.shape: (7082,), labels.shape: (7082,)
macro_test_all: 0.954339190529079, f1_test_all: 0.9174917491749175, macro_test: 0.9571979227291041, f1_test: 0.9228571428571428
f1_val_isr: 0.0
f1_test_isr: 0.9228571428571428
============sample global=======
7073
7839
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 520
preds.shape: (7839,), labels.shape: (7839,)
preds.shape: (7073,), labels.shape: (7073,)
macro_test_all: 0.9539525435465961, f1_test_all: 0.9167221852098602, macro_test: 0.956806986117331, f1_test: 0.922077922077922
f1_val_isr: 0.0
f1_test_isr: 0.922077922077922
============sample global=======
7063
7829
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 530
preds.shape: (7829,), labels.shape: (7829,)
preds.shape: (7063,), labels.shape: (7063,)
macro_test_all: 0.954287517069266, f1_test_all: 0.9173333333333333, macro_test: 0.9571727986938894, f1_test: 0.9227436823104693
f1_val_isr: 0.0
f1_test_isr: 0.9227436823104693
============sample global=======
7055
7819
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 540
preds.shape: (7819,), labels.shape: (7819,)
preds.shape: (7055,), labels.shape: (7055,)
macro_test_all: 0.9541852522393794, f1_test_all: 0.9170600134861768, macro_test: 0.9567776870638927, f1_test: 0.9219547775346463
f1_val_isr: 0.0
f1_test_isr: 0.9219547775346463
============sample global=======
7046
7809
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 550
preds.shape: (7809,), labels.shape: (7809,)
preds.shape: (7046,), labels.shape: (7046,)
macro_test_all: 0.9541237175690361, f1_test_all: 0.9169480081026333, macro_test: 0.956715396737829, f1_test: 0.9218407596785975
f1_val_isr: 0.0
f1_test_isr: 0.9218407596785975
============sample global=======
7036
7799
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 560
preds.shape: (7799,), labels.shape: (7799,)
preds.shape: (7036,), labels.shape: (7036,)
macro_test_all: 0.9540174991745674, f1_test_all: 0.9166666666666666, macro_test: 0.9566321499013807, f1_test: 0.9215976331360947
f1_val_isr: 0.0
f1_test_isr: 0.9215976331360947
============sample global=======
7027
7789
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 570
preds.shape: (7789,), labels.shape: (7789,)
preds.shape: (7027,), labels.shape: (7027,)
macro_test_all: 0.9537848941173541, f1_test_all: 0.9162087912087913, macro_test: 0.9563955312652205, f1_test: 0.9211309523809524
f1_val_isr: 0.0
f1_test_isr: 0.9211309523809524
============sample global=======
7018
7779
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 580
preds.shape: (7779,), labels.shape: (7779,)
preds.shape: (7018,), labels.shape: (7018,)
macro_test_all: 0.9532013898778611, f1_test_all: 0.915041782729805, macro_test: 0.9558602209872631, f1_test: 0.9200603318250378
f1_val_isr: 0.0
f1_test_isr: 0.9200603318250378
============sample global=======
7009
7769
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 590
preds.shape: (7769,), labels.shape: (7769,)
preds.shape: (7009,), labels.shape: (7009,)
macro_test_all: 0.9533159283659336, f1_test_all: 0.9152067274001401, macro_test: 0.9560629352355683, f1_test: 0.9203942380591357
f1_val_isr: 0.0
f1_test_isr: 0.9203942380591357
============sample global=======
6999
7759
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 600
preds.shape: (7759,), labels.shape: (7759,)
preds.shape: (6999,), labels.shape: (6999,)
macro_test_all: 0.9539655739327328, f1_test_all: 0.9163738580463808, macro_test: 0.956775948404334, f1_test: 0.9216730038022815
f1_val_isr: 0.0
f1_test_isr: 0.9216730038022815
============sample global=======
6991
7749
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 610
preds.shape: (7749,), labels.shape: (7749,)
preds.shape: (6991,), labels.shape: (6991,)
macro_test_all: 0.954259768012822, f1_test_all: 0.9169014084507042, macro_test: 0.9571027922690434, f1_test: 0.9222560975609756
f1_val_isr: 0.0
f1_test_isr: 0.9222560975609756
============sample global=======
6984
7739
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 620
preds.shape: (7739,), labels.shape: (7739,)
preds.shape: (6984,), labels.shape: (6984,)
macro_test_all: 0.9601446780830154, f1_test_all: 0.9276177090653549, macro_test: 0.9614098038970738, f1_test: 0.9300911854103344
f1_val_isr: 0.0
f1_test_isr: 0.9300911854103344
============sample global=======
6976
7729
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 630
preds.shape: (7729,), labels.shape: (7729,)
preds.shape: (6976,), labels.shape: (6976,)
macro_test_all: 0.9609797815796701, f1_test_all: 0.9290780141843972, macro_test: 0.9624333855811229, f1_test: 0.9319051262433052
f1_val_isr: 0.0
f1_test_isr: 0.9319051262433052
============sample global=======
6967
7719
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 640
preds.shape: (7719,), labels.shape: (7719,)
preds.shape: (6967,), labels.shape: (6967,)
macro_test_all: 0.9614598999792132, f1_test_all: 0.9298998569384835, macro_test: 0.9625678191775149, f1_test: 0.9320987654320988
f1_val_isr: 0.0
f1_test_isr: 0.9320987654320988
============sample global=======
6957
7709
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 650
preds.shape: (7709,), labels.shape: (7709,)
preds.shape: (6957,), labels.shape: (6957,)
macro_test_all: 0.9621928537186141, f1_test_all: 0.9312320916905443, macro_test: 0.9633624163210919, f1_test: 0.9335394126738795
f1_val_isr: 0.0
f1_test_isr: 0.9335394126738795
============sample global=======
6948
7699
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 660
preds.shape: (7699,), labels.shape: (7699,)
preds.shape: (6948,), labels.shape: (6948,)
macro_test_all: 0.9621391223741362, f1_test_all: 0.9311334289813487, macro_test: 0.9633066508936668, f1_test: 0.93343653250774
f1_val_isr: 0.0
f1_test_isr: 0.93343653250774
============sample global=======
6938
7689
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 670
preds.shape: (7689,), labels.shape: (7689,)
preds.shape: (6938,), labels.shape: (6938,)
macro_test_all: 0.9623094166990664, f1_test_all: 0.9314079422382672, macro_test: 0.9634996220481272, f1_test: 0.9337490257209665
f1_val_isr: 0.0
f1_test_isr: 0.9337490257209665
============sample global=======
6930
7679
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 680
preds.shape: (7679,), labels.shape: (7679,)
preds.shape: (6930,), labels.shape: (6930,)
macro_test_all: 0.9628075653838872, f1_test_all: 0.9322651128914785, macro_test: 0.96364462111265, f1_test: 0.9339622641509435
f1_val_isr: 0.0
f1_test_isr: 0.9339622641509435
============sample global=======
6924
7669
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 690
preds.shape: (7669,), labels.shape: (7669,)
preds.shape: (6924,), labels.shape: (6924,)
macro_test_all: 0.9626062193728409, f1_test_all: 0.931868131868132, macro_test: 0.9634865424992146, f1_test: 0.933649289099526
f1_val_isr: 0.0
f1_test_isr: 0.933649289099526
============sample global=======
6917
7659
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 700
preds.shape: (7659,), labels.shape: (7659,)
preds.shape: (6917,), labels.shape: (6917,)
macro_test_all: 0.962880869499254, f1_test_all: 0.9323529411764705, macro_test: 0.9637888876463436, f1_test: 0.9341792228390167
f1_val_isr: 0.0
f1_test_isr: 0.9341792228390167
============sample global=======
6908
7649
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 710
preds.shape: (7649,), labels.shape: (7649,)
preds.shape: (6908,), labels.shape: (6908,)
macro_test_all: 0.9632552769475283, f1_test_all: 0.9330389992641649, macro_test: 0.9641949463230126, f1_test: 0.9349206349206349
f1_val_isr: 0.0
f1_test_isr: 0.9349206349206349
============sample global=======
6898
7639
macro_val: 0.4736842105263158
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.0
the number of labels is 720
preds.shape: (7639,), labels.shape: (7639,)
preds.shape: (6898,), labels.shape: (6898,)
macro_test_all: 0.9636302752526534, f1_test_all: 0.9337260677466862, macro_test: 0.9646011744869817, f1_test: 0.9356632247815728
f1_val_isr: 0.0
f1_test_isr: 0.9356632247815728
AL Time: 0.42901001684367657s
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7955, self.idx_non_test is 419
finished loading dataset
current seed is 300
len(idx_non_test) is 419
len(idx_non_test): 404
macro_val: 0.6703296703296704
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5714285714285715
-------------initial results------------
micro_val: 0.7000, macro_val: 0.6703
strategy:  uncertainty
============sample only in training=======
7955
8349
macro_val: 0.5238095238095238
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.3333333333333333
the number of labels is 10
preds.shape: (8349,), labels.shape: (8349,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.5473057634490417, f1_test_all: 0.3035806953814219, macro_test: 0.5470958477701029, f1_test: 0.3030798582720087
f1_val_isr: 0.3333333333333333
f1_test_isr: 0.3030798582720087
============sample only in training=======
7955
8339
macro_val: 0.6
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.4
the number of labels is 20
preds.shape: (8339,), labels.shape: (8339,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.5394720267422014, f1_test_all: 0.18702095043433825, macro_test: 0.5397589284641389, f1_test: 0.18672423097679441
f1_val_isr: 0.4
f1_test_isr: 0.18672423097679441
============sample only in training=======
7955
8329
macro_val: 0.6
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.4
the number of labels is 30
preds.shape: (8329,), labels.shape: (8329,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.6875105424741604, f1_test_all: 0.45062034739454093, macro_test: 0.6857170204856469, f1_test: 0.44677503932878865
f1_val_isr: 0.4
f1_test_isr: 0.44677503932878865
============sample only in training=======
7955
8319
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 40
preds.shape: (8319,), labels.shape: (8319,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8443460835425454, f1_test_all: 0.7315582714971628, macro_test: 0.8425851394227222, f1_test: 0.7281105990783411
f1_val_isr: 0.8
f1_test_isr: 0.7281105990783411
============sample only in training=======
7955
8309
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 50
preds.shape: (8309,), labels.shape: (8309,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8641158858753082, f1_test_all: 0.7664670658682634, macro_test: 0.8641863840415837, f1_test: 0.7665474060822898
f1_val_isr: 0.8
f1_test_isr: 0.7665474060822898
============sample only in training=======
7955
8299
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 60
preds.shape: (8299,), labels.shape: (8299,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8845116409323929, f1_test_all: 0.7998192498870311, macro_test: 0.8844005749890695, f1_test: 0.7996228194247996
f1_val_isr: 0.8
f1_test_isr: 0.7996228194247996
============sample only in training=======
7955
8289
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 70
preds.shape: (8289,), labels.shape: (8289,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9014426316489355, f1_test_all: 0.827652424387902, macro_test: 0.9004910136592379, f1_test: 0.826
f1_val_isr: 0.8
f1_test_isr: 0.826
============sample only in training=======
7955
8279
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 80
preds.shape: (8279,), labels.shape: (8279,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8620856979651583, f1_test_all: 0.7559055118110236, macro_test: 0.8607382995790516, f1_test: 0.7536704730831973
f1_val_isr: 0.5
f1_test_isr: 0.7536704730831973
============sample only in training=======
7955
8269
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 90
preds.shape: (8269,), labels.shape: (8269,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8872739063025614, f1_test_all: 0.801226366888094, macro_test: 0.8848916534360705, f1_test: 0.7972617166929962
f1_val_isr: 0.8
f1_test_isr: 0.7972617166929962
============sample only in training=======
7955
8259
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 100
preds.shape: (8259,), labels.shape: (8259,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8894310863512873, f1_test_all: 0.8051020408163266, macro_test: 0.8875038362264777, f1_test: 0.8020887728459528
f1_val_isr: 0.8
f1_test_isr: 0.8020887728459528
============sample only in training=======
7955
8249
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 110
preds.shape: (8249,), labels.shape: (8249,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8916876955861159, f1_test_all: 0.8088614116434827, macro_test: 0.8900244186483338, f1_test: 0.8063157894736841
f1_val_isr: 0.8
f1_test_isr: 0.8063157894736841
============sample only in training=======
7955
8239
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 120
preds.shape: (8239,), labels.shape: (8239,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8970179882410658, f1_test_all: 0.818322182192486, macro_test: 0.895688250366482, f1_test: 0.8163693599160545
f1_val_isr: 0.8
f1_test_isr: 0.8163693599160545
============sample only in training=======
7955
8229
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 130
preds.shape: (8229,), labels.shape: (8229,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8964488558036945, f1_test_all: 0.8174358974358974, macro_test: 0.8951266945000276, f1_test: 0.8154730789336121
f1_val_isr: 0.8
f1_test_isr: 0.8154730789336121
============sample only in training=======
7955
8219
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 140
preds.shape: (8219,), labels.shape: (8219,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8999229778136459, f1_test_all: 0.8235897435897436, macro_test: 0.8990559958447311, f1_test: 0.8224882873503384
f1_val_isr: 0.8
f1_test_isr: 0.8224882873503384
============sample only in training=======
7955
8209
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 150
preds.shape: (8209,), labels.shape: (8209,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8991666247973036, f1_test_all: 0.8220031136481577, macro_test: 0.8982995758264706, f1_test: 0.82086406743941
f1_val_isr: 0.8
f1_test_isr: 0.82086406743941
============sample only in training=======
7955
8199
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 160
preds.shape: (8199,), labels.shape: (8199,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8989925237902192, f1_test_all: 0.821761658031088, macro_test: 0.8982321390914783, f1_test: 0.8208092485549133
f1_val_isr: 0.8
f1_test_isr: 0.8208092485549133
============sample only in training=======
7955
8189
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 170
preds.shape: (8189,), labels.shape: (8189,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.900898288175811, f1_test_all: 0.8251167618059159, macro_test: 0.9002759276507761, f1_test: 0.8243953732912723
f1_val_isr: 0.8
f1_test_isr: 0.8243953732912723
============sample only in training=======
7955
8179
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 180
preds.shape: (8179,), labels.shape: (8179,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.8958261462337493, f1_test_all: 0.8159412690089145, macro_test: 0.895621214282935, f1_test: 0.8160676532769555
f1_val_isr: 0.8
f1_test_isr: 0.8160676532769555
============sample only in training=======
7955
8169
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 190
preds.shape: (8169,), labels.shape: (8169,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9026545651415658, f1_test_all: 0.8284389489953632, macro_test: 0.9022794043668043, f1_test: 0.8282304099636739
f1_val_isr: 0.8
f1_test_isr: 0.8282304099636739
============sample only in training=======
7955
8159
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 200
preds.shape: (8159,), labels.shape: (8159,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.904746965107452, f1_test_all: 0.8325746079919069, macro_test: 0.9041564305498397, f1_test: 0.8319755600814663
f1_val_isr: 0.8
f1_test_isr: 0.8319755600814663
============sample only in training=======
7955
8149
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 210
preds.shape: (8149,), labels.shape: (8149,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9057173881750291, f1_test_all: 0.8341810783316379, macro_test: 0.905151771656497, f1_test: 0.833589349718382
f1_val_isr: 0.8
f1_test_isr: 0.833589349718382
============sample only in training=======
7955
8139
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 220
preds.shape: (8139,), labels.shape: (8139,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9029874604734391, f1_test_all: 0.8295397066262012, macro_test: 0.9024138201962004, f1_test: 0.8289205702647658
f1_val_isr: 0.8
f1_test_isr: 0.8289205702647658
============sample only in training=======
7955
8129
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 230
preds.shape: (8129,), labels.shape: (8129,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9018815060807539, f1_test_all: 0.8274809160305344, macro_test: 0.9013143793206316, f1_test: 0.8268442622950819
f1_val_isr: 0.8
f1_test_isr: 0.8268442622950819
============sample only in training=======
7955
8119
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 240
preds.shape: (8119,), labels.shape: (8119,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9014840100871437, f1_test_all: 0.827029752899647, macro_test: 0.9009311115804499, f1_test: 0.8263959390862944
f1_val_isr: 0.8
f1_test_isr: 0.8263959390862944
============sample only in training=======
7955
8109
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 250
preds.shape: (8109,), labels.shape: (8109,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.901368805422472, f1_test_all: 0.8267477203647418, macro_test: 0.9009182970200009, f1_test: 0.826286296484972
f1_val_isr: 0.8
f1_test_isr: 0.826286296484972
============sample only in training=======
7955
8099
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 260
preds.shape: (8099,), labels.shape: (8099,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9019288147492204, f1_test_all: 0.827760891590679, macro_test: 0.9014994213776548, f1_test: 0.8273051451859399
f1_val_isr: 0.8
f1_test_isr: 0.8273051451859399
============sample only in training=======
7955
8089
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 270
preds.shape: (8089,), labels.shape: (8089,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9020501502362678, f1_test_all: 0.8277976494634645, macro_test: 0.9016381280538446, f1_test: 0.827338129496403
f1_val_isr: 0.8
f1_test_isr: 0.827338129496403
============sample only in training=======
7955
8079
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 280
preds.shape: (8079,), labels.shape: (8079,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9073692400585754, f1_test_all: 0.8367983367983368, macro_test: 0.9068393612174379, f1_test: 0.8361169102296452
f1_val_isr: 0.8
f1_test_isr: 0.8361169102296452
============sample only in training=======
7955
8069
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 290
preds.shape: (8069,), labels.shape: (8069,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9060800506173465, f1_test_all: 0.8340425531914893, macro_test: 0.9059022459471345, f1_test: 0.8340425531914893
f1_val_isr: 0.8
f1_test_isr: 0.8340425531914893
============sample only in training=======
7955
8059
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 300
preds.shape: (8059,), labels.shape: (8059,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9044675437330338, f1_test_all: 0.8316831683168318, macro_test: 0.9042984492859979, f1_test: 0.8316831683168318
f1_val_isr: 0.8
f1_test_isr: 0.8316831683168318
============sample only in training=======
7955
8049
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 310
preds.shape: (8049,), labels.shape: (8049,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9055445536857416, f1_test_all: 0.8334209143457698, macro_test: 0.9053946864867994, f1_test: 0.8334209143457698
f1_val_isr: 0.8
f1_test_isr: 0.8334209143457698
============sample only in training=======
7955
8039
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 320
preds.shape: (8039,), labels.shape: (8039,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9063802537663812, f1_test_all: 0.8349106203995794, macro_test: 0.906247428989053, f1_test: 0.8349106203995794
f1_val_isr: 0.8
f1_test_isr: 0.8349106203995794
============sample only in training=======
7955
8029
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 330
preds.shape: (8029,), labels.shape: (8029,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9053407250484521, f1_test_all: 0.8330700368615062, macro_test: 0.9052224782837257, f1_test: 0.8330700368615062
f1_val_isr: 0.8
f1_test_isr: 0.8330700368615062
============sample only in training=======
7955
8019
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 340
preds.shape: (8019,), labels.shape: (8019,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9030794405979943, f1_test_all: 0.8289054197662062, macro_test: 0.9029756639749196, f1_test: 0.8289054197662062
f1_val_isr: 0.8
f1_test_isr: 0.8289054197662062
============sample only in training=======
7955
8009
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 350
preds.shape: (8009,), labels.shape: (8009,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9048932588827372, f1_test_all: 0.8325508607198749, macro_test: 0.9048054096352893, f1_test: 0.8325508607198749
f1_val_isr: 0.8
f1_test_isr: 0.8325508607198749
============sample only in training=======
7955
7999
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 360
preds.shape: (7999,), labels.shape: (7999,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9068229889175388, f1_test_all: 0.8360229047371162, macro_test: 0.9067526061322295, f1_test: 0.8360229047371162
f1_val_isr: 0.8
f1_test_isr: 0.8360229047371162
============sample only in training=======
7955
7989
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 370
preds.shape: (7989,), labels.shape: (7989,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9073782187092405, f1_test_all: 0.8373524884556184, macro_test: 0.9073231892890512, f1_test: 0.8373524884556184
f1_val_isr: 0.8
f1_test_isr: 0.8373524884556184
============sample only in training=======
7955
7979
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 380
preds.shape: (7979,), labels.shape: (7979,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9056089054028, f1_test_all: 0.8341915550978374, macro_test: 0.9055694316153562, f1_test: 0.8341915550978374
f1_val_isr: 0.8
f1_test_isr: 0.8341915550978374
============sample only in training=======
7955
7969
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 390
preds.shape: (7969,), labels.shape: (7969,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9049069001769918, f1_test_all: 0.8325459317585301, macro_test: 0.9048841761613071, f1_test: 0.8325459317585301
f1_val_isr: 0.8
f1_test_isr: 0.8325459317585301
============sample only in training=======
7955
7959
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 400
preds.shape: (7959,), labels.shape: (7959,)
preds.shape: (7955,), labels.shape: (7955,)
macro_test_all: 0.9053986592497505, f1_test_all: 0.8333333333333334, macro_test: 0.9053922268207983, f1_test: 0.8333333333333334
f1_val_isr: 0.8
f1_test_isr: 0.8333333333333334
AL Time: 0.17937372904270887s
start loading J01Network
start constructing adj
tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
start loading features
start loading labels
self.labels: (tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0'), torch.Size([9424]))
self.adj: tensor(indices=tensor([[   8,    8,   21,  ..., 9423, 9423, 9423],
                       [2170, 5213, 1474,  ..., 9418, 9419, 9421]]),
       values=tensor([0.5000, 0.5000, 0.2500,  ..., 0.3333, 0.3333, 0.3333]),
       device='cuda:0', size=(9424, 9424), nnz=181292, layout=torch.sparse_coo)
self.feature: (tensor([[2.9971e-01, 6.0465e-02, 3.8314e-03,  ..., 6.8966e-02, 7.1024e-02,
         8.2219e-01],
        [1.3132e-01, 4.6512e-02, 7.6628e-03,  ..., 7.2464e-02, 7.0725e-02,
         8.4524e-01],
        [3.4525e-01, 4.6512e-02, 2.5543e-03,  ..., 7.9646e-02, 5.8153e-02,
         8.5975e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 1.2771e-03,  ..., 2.2727e-01, 4.6209e-02,
         8.7654e-01],
        [2.6476e-04, 4.6512e-03, 4.7254e-02,  ..., 3.7037e-02, 5.9044e-02,
         8.9359e-01],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2727e-01, 1.2836e-03,
         8.7665e-01]], device='cuda:0'), torch.Size([9424, 10]))
self.idx_test is 7955, self.idx_non_test is 419
finished loading dataset
current seed is 300
len(idx_non_test) is 419
len(idx_non_test): 404
macro_val: 0.6703296703296704
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5714285714285715
-------------initial results------------
micro_val: 0.7000, macro_val: 0.6703
strategy:  uncertainty
============sample global=======
7945
8349
macro_val: 0.6703296703296704
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5714285714285715
the number of labels is 10
preds.shape: (8349,), labels.shape: (8349,)
preds.shape: (7945,), labels.shape: (7945,)
macro_test_all: 0.6343487781272328, f1_test_all: 0.44532606000495906, macro_test: 0.631985179929035, f1_test: 0.4411918452692106
f1_val_isr: 0.5714285714285715
f1_test_isr: 0.4411918452692106
============sample global=======
7935
8339
macro_val: 0.5238095238095238
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.3333333333333333
the number of labels is 20
preds.shape: (8339,), labels.shape: (8339,)
preds.shape: (7935,), labels.shape: (7935,)
macro_test_all: 0.5805767558376491, f1_test_all: 0.28820269200316706, macro_test: 0.5812574239049741, f1_test: 0.2891666666666667
f1_val_isr: 0.3333333333333333
f1_test_isr: 0.2891666666666667
============sample global=======
7925
8329
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 30
preds.shape: (8329,), labels.shape: (8329,)
preds.shape: (7925,), labels.shape: (7925,)
macro_test_all: 0.7351071682653585, f1_test_all: 0.5345849802371542, macro_test: 0.7351544349693102, f1_test: 0.5342394145321484
f1_val_isr: 0.5
f1_test_isr: 0.5342394145321484
============sample global=======
7916
8319
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 40
preds.shape: (8319,), labels.shape: (8319,)
preds.shape: (7916,), labels.shape: (7916,)
macro_test_all: 0.7632563410015213, f1_test_all: 0.5925925925925927, macro_test: 0.7612060946493693, f1_test: 0.5887170154686079
f1_val_isr: 0.5
f1_test_isr: 0.5887170154686079
============sample global=======
7906
8309
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 50
preds.shape: (8309,), labels.shape: (8309,)
preds.shape: (7906,), labels.shape: (7906,)
macro_test_all: 0.8094694840734993, f1_test_all: 0.6748667486674866, macro_test: 0.8082771253661836, f1_test: 0.6724511930585683
f1_val_isr: 0.8
f1_test_isr: 0.6724511930585683
============sample global=======
7896
8299
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 60
preds.shape: (8299,), labels.shape: (8299,)
preds.shape: (7896,), labels.shape: (7896,)
macro_test_all: 0.732760321582479, f1_test_all: 0.5378450578806768, macro_test: 0.7341632825093187, f1_test: 0.5398021667451719
f1_val_isr: 0.5
f1_test_isr: 0.5398021667451719
============sample global=======
7886
8289
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 70
preds.shape: (8289,), labels.shape: (8289,)
preds.shape: (7886,), labels.shape: (7886,)
macro_test_all: 0.7435498461559836, f1_test_all: 0.5538033395176252, macro_test: 0.7447394223600434, f1_test: 0.5554465161923454
f1_val_isr: 0.5
f1_test_isr: 0.5554465161923454
============sample global=======
7877
8279
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 80
preds.shape: (8279,), labels.shape: (8279,)
preds.shape: (7877,), labels.shape: (7877,)
macro_test_all: 0.7722506791201484, f1_test_all: 0.5988872028325746, macro_test: 0.7734707244359048, f1_test: 0.6007482629609835
f1_val_isr: 0.5
f1_test_isr: 0.6007482629609835
============sample global=======
7867
8269
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 90
preds.shape: (8269,), labels.shape: (8269,)
preds.shape: (7867,), labels.shape: (7867,)
macro_test_all: 0.7811440682279505, f1_test_all: 0.6119402985074628, macro_test: 0.7827197684793503, f1_test: 0.614518851997749
f1_val_isr: 0.5
f1_test_isr: 0.614518851997749
============sample global=======
7857
8259
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 100
preds.shape: (8259,), labels.shape: (8259,)
preds.shape: (7857,), labels.shape: (7857,)
macro_test_all: 0.7911213782895536, f1_test_all: 0.6278424847476428, macro_test: 0.7922049071749641, f1_test: 0.6296079578700994
f1_val_isr: 0.5
f1_test_isr: 0.6296079578700994
============sample global=======
7847
8249
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 110
preds.shape: (8249,), labels.shape: (8249,)
preds.shape: (7847,), labels.shape: (7847,)
macro_test_all: 0.7934707172132665, f1_test_all: 0.6312817617165443, macro_test: 0.7951405613064042, f1_test: 0.6340882002383791
f1_val_isr: 0.5
f1_test_isr: 0.6340882002383791
============sample global=======
7838
8239
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 120
preds.shape: (8239,), labels.shape: (8239,)
preds.shape: (7838,), labels.shape: (7838,)
macro_test_all: 0.8033717578758677, f1_test_all: 0.6495821727019498, macro_test: 0.8051337580019751, f1_test: 0.652557319223986
f1_val_isr: 0.5
f1_test_isr: 0.652557319223986
============sample global=======
7828
8229
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 130
preds.shape: (8229,), labels.shape: (8229,)
preds.shape: (7828,), labels.shape: (7828,)
macro_test_all: 0.8078918740577934, f1_test_all: 0.6568013659647126, macro_test: 0.8090296103267801, f1_test: 0.658653846153846
f1_val_isr: 0.5
f1_test_isr: 0.658653846153846
============sample global=======
7818
8219
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 140
preds.shape: (8219,), labels.shape: (8219,)
preds.shape: (7818,), labels.shape: (7818,)
macro_test_all: 0.8120194924040461, f1_test_all: 0.6639954207212364, macro_test: 0.8131536735980273, f1_test: 0.6658610271903324
f1_val_isr: 0.5
f1_test_isr: 0.6658610271903324
============sample global=======
7809
8209
macro_val: 0.6875
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.5
the number of labels is 150
preds.shape: (8209,), labels.shape: (8209,)
preds.shape: (7809,), labels.shape: (7809,)
macro_test_all: 0.8142625005142291, f1_test_all: 0.6674418604651162, macro_test: 0.815738555922605, f1_test: 0.6699386503067485
f1_val_isr: 0.5
f1_test_isr: 0.6699386503067485
============sample global=======
7800
8199
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 160
preds.shape: (8199,), labels.shape: (8199,)
preds.shape: (7800,), labels.shape: (7800,)
macro_test_all: 0.8967668617903026, f1_test_all: 0.8177083333333335, macro_test: 0.8968096235877421, f1_test: 0.8176308539944904
f1_val_isr: 0.8
f1_test_isr: 0.8176308539944904
============sample global=======
7790
8189
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 170
preds.shape: (8189,), labels.shape: (8189,)
preds.shape: (7790,), labels.shape: (7790,)
macro_test_all: 0.915710909449957, f1_test_all: 0.8516063233044365, macro_test: 0.9148207129443631, f1_test: 0.8498920086393088
f1_val_isr: 0.8
f1_test_isr: 0.8498920086393088
============sample global=======
7780
8179
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 180
preds.shape: (8179,), labels.shape: (8179,)
preds.shape: (7780,), labels.shape: (7780,)
macro_test_all: 0.9175431212831437, f1_test_all: 0.8548057259713701, macro_test: 0.9166785718167061, f1_test: 0.8531165311653116
f1_val_isr: 0.8
f1_test_isr: 0.8531165311653116
============sample global=======
7770
8169
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 190
preds.shape: (8169,), labels.shape: (8169,)
preds.shape: (7770,), labels.shape: (7770,)
macro_test_all: 0.9200369261588945, f1_test_all: 0.8591909882232462, macro_test: 0.9193182104617855, f1_test: 0.8577633007600435
f1_val_isr: 0.8
f1_test_isr: 0.8577633007600435
============sample global=======
7761
8159
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 200
preds.shape: (8159,), labels.shape: (8159,)
preds.shape: (7761,), labels.shape: (7761,)
macro_test_all: 0.9248678687682029, f1_test_all: 0.8676923076923078, macro_test: 0.9245769513268672, f1_test: 0.8670645686380901
f1_val_isr: 0.8
f1_test_isr: 0.8670645686380901
============sample global=======
7752
8149
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 210
preds.shape: (8149,), labels.shape: (8149,)
preds.shape: (7752,), labels.shape: (7752,)
macro_test_all: 0.9259503799659372, f1_test_all: 0.8695203713254256, macro_test: 0.9254464962867748, f1_test: 0.8685215493726132
f1_val_isr: 0.8
f1_test_isr: 0.8685215493726132
============sample global=======
7742
8139
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 220
preds.shape: (8139,), labels.shape: (8139,)
preds.shape: (7742,), labels.shape: (7742,)
macro_test_all: 0.928413005650493, f1_test_all: 0.873836608066184, macro_test: 0.9277038398620612, f1_test: 0.8724685276409415
f1_val_isr: 0.8
f1_test_isr: 0.8724685276409415
============sample global=======
7733
8129
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 230
preds.shape: (8129,), labels.shape: (8129,)
preds.shape: (7733,), labels.shape: (7733,)
macro_test_all: 0.930964638188457, f1_test_all: 0.8782518210197711, macro_test: 0.9301208629842992, f1_test: 0.8766519823788547
f1_val_isr: 0.8
f1_test_isr: 0.8766519823788547
============sample global=======
7723
8119
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 240
preds.shape: (8119,), labels.shape: (8119,)
preds.shape: (7723,), labels.shape: (7723,)
macro_test_all: 0.9295276414595248, f1_test_all: 0.8755905511811023, macro_test: 0.9288727901393629, f1_test: 0.8743047830923248
f1_val_isr: 0.8
f1_test_isr: 0.8743047830923248
============sample global=======
7714
8109
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 250
preds.shape: (8109,), labels.shape: (8109,)
preds.shape: (7714,), labels.shape: (7714,)
macro_test_all: 0.9320999732932114, f1_test_all: 0.8801261829652997, macro_test: 0.9316617940210999, f1_test: 0.8792431830829159
f1_val_isr: 0.8
f1_test_isr: 0.8792431830829159
============sample global=======
7705
8099
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 260
preds.shape: (8099,), labels.shape: (8099,)
preds.shape: (7705,), labels.shape: (7705,)
macro_test_all: 0.9286627731646946, f1_test_all: 0.8737967914438503, macro_test: 0.9280867804493607, f1_test: 0.8726655348047538
f1_val_isr: 0.8
f1_test_isr: 0.8726655348047538
============sample global=======
7695
8089
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 270
preds.shape: (8089,), labels.shape: (8089,)
preds.shape: (7695,), labels.shape: (7695,)
macro_test_all: 0.933944263441236, f1_test_all: 0.8832, macro_test: 0.9333206850677647, f1_test: 0.8819875776397516
f1_val_isr: 0.8
f1_test_isr: 0.8819875776397516
============sample global=======
7685
8079
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 280
preds.shape: (8079,), labels.shape: (8079,)
preds.shape: (7685,), labels.shape: (7685,)
macro_test_all: 0.934716297392121, f1_test_all: 0.8844707146695325, macro_test: 0.9341323564082862, f1_test: 0.8833238474672738
f1_val_isr: 0.8
f1_test_isr: 0.8833238474672738
============sample global=======
7676
8069
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 290
preds.shape: (8069,), labels.shape: (8069,)
preds.shape: (7676,), labels.shape: (7676,)
macro_test_all: 0.9344883113130609, f1_test_all: 0.8839479392624728, macro_test: 0.933952123742335, f1_test: 0.8828932261768083
f1_val_isr: 0.8
f1_test_isr: 0.8828932261768083
============sample global=======
7666
8059
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 300
preds.shape: (8059,), labels.shape: (8059,)
preds.shape: (7666,), labels.shape: (7666,)
macro_test_all: 0.9368078436268628, f1_test_all: 0.8880434782608695, macro_test: 0.9364042858548067, f1_test: 0.8872266973532796
f1_val_isr: 0.8
f1_test_isr: 0.8872266973532796
============sample global=======
7657
8049
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 310
preds.shape: (8049,), labels.shape: (8049,)
preds.shape: (7657,), labels.shape: (7657,)
macro_test_all: 0.9377299654850704, f1_test_all: 0.8896174863387978, macro_test: 0.937083968662916, f1_test: 0.8883747831116252
f1_val_isr: 0.8
f1_test_isr: 0.8883747831116252
============sample global=======
7647
8039
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 320
preds.shape: (8039,), labels.shape: (8039,)
preds.shape: (7647,), labels.shape: (7647,)
macro_test_all: 0.9393386542581567, f1_test_all: 0.8924259055982438, macro_test: 0.9387824453929862, f1_test: 0.8913422428820454
f1_val_isr: 0.8
f1_test_isr: 0.8913422428820454
============sample global=======
7638
8029
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 330
preds.shape: (8029,), labels.shape: (8029,)
preds.shape: (7638,), labels.shape: (7638,)
macro_test_all: 0.9402235382071653, f1_test_all: 0.8939226519337017, macro_test: 0.9394790222606845, f1_test: 0.8925233644859812
f1_val_isr: 0.8
f1_test_isr: 0.8925233644859812
============sample global=======
7629
8019
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 340
preds.shape: (8019,), labels.shape: (8019,)
preds.shape: (7629,), labels.shape: (7629,)
macro_test_all: 0.9452370187213, f1_test_all: 0.9026845637583892, macro_test: 0.944466294423231, f1_test: 0.9012418687167355
f1_val_isr: 0.8
f1_test_isr: 0.9012418687167355
============sample global=======
7619
8009
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 350
preds.shape: (8009,), labels.shape: (8009,)
preds.shape: (7619,), labels.shape: (7619,)
macro_test_all: 0.948362397936026, f1_test_all: 0.908169014084507, macro_test: 0.9474564672489292, f1_test: 0.9064919594997023
f1_val_isr: 0.8
f1_test_isr: 0.9064919594997023
============sample global=======
7610
7999
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 360
preds.shape: (7999,), labels.shape: (7999,)
preds.shape: (7610,), labels.shape: (7610,)
macro_test_all: 0.9499092530172979, f1_test_all: 0.9108461101646792, macro_test: 0.9490847542489003, f1_test: 0.9093093093093093
f1_val_isr: 0.8
f1_test_isr: 0.9093093093093093
============sample global=======
7601
7989
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 370
preds.shape: (7989,), labels.shape: (7989,)
preds.shape: (7601,), labels.shape: (7601,)
macro_test_all: 0.9508843763256423, f1_test_all: 0.9125214408233276, macro_test: 0.9497979149954179, f1_test: 0.9105199516324063
f1_val_isr: 0.8
f1_test_isr: 0.9105199516324063
============sample global=======
7591
7979
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 380
preds.shape: (7979,), labels.shape: (7979,)
preds.shape: (7591,), labels.shape: (7591,)
macro_test_all: 0.9519682954736579, f1_test_all: 0.9144170017231477, macro_test: 0.950938445231509, f1_test: 0.9125151883353584
f1_val_isr: 0.8
f1_test_isr: 0.9125151883353584
============sample global=======
7581
7969
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 390
preds.shape: (7969,), labels.shape: (7969,)
preds.shape: (7581,), labels.shape: (7581,)
macro_test_all: 0.9529658476545364, f1_test_all: 0.9161364950838634, macro_test: 0.9519858897308597, f1_test: 0.9143206854345165
f1_val_isr: 0.8
f1_test_isr: 0.9143206854345165
============sample global=======
7571
7959
macro_val: 0.8666666666666667
preds.shape: (10,), labels.shape: (10,)
f1_val_isr: 0.8
the number of labels is 400
preds.shape: (7959,), labels.shape: (7959,)
preds.shape: (7571,), labels.shape: (7571,)
macro_test_all: 0.9529240041837443, f1_test_all: 0.9159859976662776, macro_test: 0.9519328746846645, f1_test: 0.9141445336627547
f1_val_isr: 0.8
f1_test_isr: 0.9141445336627547
AL Time: 0.25265453150495887s
